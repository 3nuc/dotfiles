**** BEGIN LOGGING AT Sat Aug 31 11:23:00 2019

Aug 31 11:23:00 *	Now talking on #docker
Aug 31 11:23:00 *	Topic for #docker is: Docker: Open platform for distributed applications | http://docker.com | Certifications https://success.docker.com/certification | http://github.com/moby/moby | Current Status: http://status.docker.com/ | https://forums.docker.com/ | Registration with NickServ required: https://freenode.net/kb/answer/registration
Aug 31 11:23:00 *	Topic for #docker set by programmerq!~jeff@unaffiliated/programmerq (Fri Dec  7 20:42:52 2018)
Aug 31 12:31:19 <mgolisch>	how does that new docker for windows wsl2 stuff work?
Aug 31 12:31:41 <mgolisch>	does it run the docker engine inside the wsl2 distro?
Aug 31 12:34:39 <mgolisch>	if so why do i need to install docker for windows at all then?
Aug 31 14:05:47 <cluelessperson>	okay I'm stuck and this is driving me nuts
Aug 31 14:06:00 <cluelessperson>	docker-compose says   "address already in use" and errors bringing a container up
Aug 31 14:06:08 <cluelessperson>	except that address is definitely NOT in use.
Aug 31 14:06:13 <cluelessperson>	I tried rebooting evein
Aug 31 14:10:34 <bozzle>	So I went back to basics and tried to follow this: https://docs.docker.com/docker-for-mac/. I got to step 3 which looked fine in the terminal, but I got 'This site can’t be reached' on localhost
Aug 31 14:11:19 <cluelessperson>	bozzle   do     docker container ls      is that container running?
Aug 31 14:11:31 <bozzle>	What I can find out there said something about httpd (have no idea what that is or how to discover if it's the problem) or maybe a proxy, which I also don't know how to discover.
Aug 31 14:11:52 <bozzle>	cluelessperson: Yeah, that container is running.
Aug 31 14:12:54 <cluelessperson>	bozzle  what did you type into the address bar exactly?    http://localhost    https://localhost    localhost ?
Aug 31 14:13:07 <bozzle>	Just `localhost`
Aug 31 14:13:20 <bozzle>	Also tried http://127.0.0.1/
Aug 31 14:13:48 <bozzle>	cluelessperson
Aug 31 14:13:48 <cluelessperson>	bozzle   does   docker container ls   report that container is listening/exposed on port 80?
Aug 31 14:14:22 <bozzle>	cluelessperson: `0.0.0.0:80->80/tcp` under `ports`
Aug 31 14:15:00 <cluelessperson>	did you change the configuration elsewise?
Aug 31 14:15:29 <bozzle>	cluelessperson: I don't think so, but how can I check?
Aug 31 14:15:54 <cluelessperson>	what's the exact run command you used?
Aug 31 14:16:01 <cluelessperson>	you can also do.   docker logs container
Aug 31 14:16:07 <bozzle>	The one from the tutorial
Aug 31 14:16:53 <bozzle>	cluelessperson: logs doesn't show me anything.
Aug 31 14:17:23 <bozzle>	Jut goes right back to command prompt
Aug 31 14:23:22 <bozzle>	cluelessperson?
Aug 31 14:23:51 <cluelessperson>	bozzle    try     telnet localhost 80
Aug 31 14:23:57 <cluelessperson>	does that connect?
Aug 31 14:24:31 <bozzle>	cluelessperson: No, `connection refused`
Aug 31 14:26:40 <cluelessperson>	bozzle  are you running docker on the mac directly, or another machine?
Aug 31 14:26:44 <cluelessperson>	or in a virtual machine?
Aug 31 14:27:06 <bozzle>	cluelessperson: I think it's in my mac directly
Aug 31 14:27:27 <bozzle>	That is, I don't have virtual box open or anything.
Aug 31 14:27:54 <bozzle>	If it did it's own virtual machine thing in the background secretly without doing anything visible, then maybe that's a thing...
Aug 31 14:28:03 <cluelessperson>	bozzle  can you also try  telnet 127.0.0.1 80      and try your local network ip as well
Aug 31 14:28:18 <cluelessperson>	it doesn't do any secret virtual machine thing
Aug 31 14:28:26 <bozzle>	Heh
Aug 31 14:28:46 <bozzle>	The one you just said also has connection refused. I'll try my IP
Aug 31 14:29:07 <bozzle>	cluelessperson: How do I find out my local network IP? How is that different from other IPs?
Aug 31 14:31:00 <bozzle>	cluelessperson: Found these instructions: http://osxdaily.com/2010/08/08/lan-ip-address-mac/. Used that address and got `Connection refused` again.
Aug 31 14:31:45 <cluelessperson>	I think there's a bug in the docker network driver/storage.   I had to delete the network and recreate it in order to reuse this address.
Aug 31 14:31:53 <cluelessperson>	double checking my network config as well.
Aug 31 14:32:37 <cluelessperson>	bozzle   So, servers can have multiple network connections attached to them.  Most laptops for example will have wifi, lan, and they can have more.
Aug 31 14:33:06 <cluelessperson>	So, you might sometimes define a "bind" address.   0.0.0.0 is designed so that it listens on "all" of them.
Aug 31 14:33:36 <bozzle>	Should I test that one?
Aug 31 14:33:58 <cluelessperson>	bozzle  no.   it leads nowhere.
Aug 31 14:34:13 <cluelessperson>	bozzle  OH, I remember now.  Yeah, docker on mac DOES run in a virtual machine.
Aug 31 14:34:57 <cluelessperson>	do,   ip a    and you might spot another interface/network in the background.
Aug 31 14:35:18 <cluelessperson>	that might be the ip you need to hit.
Aug 31 14:35:30 <bozzle>	cluelessperson: `ip: command not found`
Aug 31 14:35:52 <cluelessperson>	ipconfig /a     I don't remember strictly on mac
Aug 31 14:36:46 <bozzle>	cluelessperson: getting `ipconfig <command> <args> where <command> is one of waitall, getifaddr, ifcount, getoption, getpacket, getv6packet, set, setverbose`.
Aug 31 14:37:20 <bozzle>	What can I search for on the internets to find the mac way to do it?
Aug 31 14:38:12 <cluelessperson>	ifconfig ?
Aug 31 14:39:53 <bozzle>	cluelessperson: `ifconfig -a` did a thing. What am I looking for there?
Aug 31 14:40:11 <cluelessperson>	a subnet that might be specified for virtual machines to use
Aug 31 14:40:58 <bozzle>	cluelessperson: I don't find 'subnet' anywhere in the text of the output.
Aug 31 14:41:35 <cluelessperson>	a subnet is like an ip range.   perhaps 172.62.0.1/24   or something completely different
Aug 31 14:42:15 <cluelessperson>	note ip addresses aren't usually sensitive info, so feel free to supply a paste link of the output and I can glance at it
Aug 31 14:47:58 <cluelessperson>	bozzle   do    docker inspect <contianer_name>    and see what its ip address is.
Aug 31 14:48:08 <cluelessperson>	it may have an ipv4 and/or ipv6 address.
Aug 31 14:48:12 <cluelessperson>	try that.
Aug 31 14:49:57 <bozzle>	cluelessperson: I don't see `v4` anywhere. `v6` stuff has values like empty string, null, and length of 0.
Aug 31 14:51:29 <cluelessperson>	bozzle   docker inspect pihole | grep IPAddress
Aug 31 14:51:57 <bozzle>	cluelessperson: `Error: No such object: pihole`
Aug 31 14:52:09 <cluelessperson>	replace pihole with your container's name
Aug 31 14:52:45 <bozzle>	lol
Aug 31 14:53:41 <bozzle>	cluelessperson: It gives me an IPAddress. With `"SecondaryIPAddresses": null,`
Aug 31 14:54:17 <cluelessperson>	sounds like some sort of configuration issue.
Aug 31 14:54:30 <cluelessperson>	how did you install docker exactly?
Aug 31 14:54:34 <bozzle>	Maybe it didn't start a vm and that's the problem?
Aug 31 14:54:56 <bozzle>	I installed the Toolbox following the directions online from the Docker site.
Aug 31 14:55:14 <cluelessperson>	bozzle  I'm not entirely clear, but my understanding is that on mac, docker runs everything in a single vm.  Can you link me to the toolbox thing?
Aug 31 14:55:24 <bozzle>	I'll try to find it again.
Aug 31 14:56:34 <bozzle>	cluelessperson: I think I did it this way: https://docs.docker.com/toolbox/toolbox_install_mac/
Aug 31 14:59:14 <cluelessperson>	bozzle  yeah, so this configuration confusion is what's hurting.   I understand this may be frustrating, but stick with it, we'll get to the bottom eventually
Aug 31 14:59:36 <cluelessperson>	try,   docker-machine ls    (if that's installed) and see if it reveals info.
Aug 31 15:00:37 <cluelessperson>	based on your   ifconfig   output from earlier, there's an internal vbox1 subnet,  192.168.99.1/24  defined, and it correlates with some of the docker-machine info I'm finding online.
Aug 31 15:00:54 <bozzle>	cluelessperson: I get `default   *        virtualbox   Running   tcp://###...:####` and the Docker version: `v18.09.6   `
Aug 31 15:01:42 <cluelessperson>	there aren't others?
Aug 31 15:01:58 <bozzle>	cluelessperson: No, just that one.
Aug 31 15:04:19 <cluelessperson>	bozzle  what does   docker-machine env   return?
Aug 31 15:04:48 <cluelessperson>	and what's that tcp://   ip address?
Aug 31 15:06:16 <bozzle>	Starts the same as the one you put up there, but instead of `.1` it's got `.100:2376`
Aug 31 15:06:39 <bozzle>	@cluelessperson
Aug 31 15:10:38 <cluelessperson>	so it seems your docker vm is at an internal 192.168.99.100  and docker is listening on 2376 there.
Aug 31 15:11:17 <bozzle>	cluelessperson: Is that a useful clue?
Aug 31 15:11:21 <cluelessperson>	btw,  https://en.wikipedia.org/wiki/Private_network
Aug 31 15:11:29 <cluelessperson>	it's leading us in the right direction
Aug 31 15:11:59 <cluelessperson>	bozzle   Basically, when you connect to localhost in your browser, your connection isn't being forwarded to that VM, which is actually where nginx is running.
Aug 31 15:12:38 <cluelessperson>	presumably, nginx is supposed to come up with 192.168.99.? and is probably connectable there.
Aug 31 15:13:00 <cluelessperson>	oh wait, maybe it's on the host net
Aug 31 15:13:18 <cluelessperson>	bozzle  try   http://192.168.99.100
Aug 31 15:13:55 <bozzle>	Wow. That worked. Wat!?
Aug 31 15:14:19 <cluelessperson>	(you can run a docker container as its own network entity, like 192.168.99.105,   or run the service so that it uses the host's ip)
Aug 31 15:14:28 <bozzle>	Would that happen on any mac or is it just something I did sometime?
Aug 31 15:14:50 <bozzle>	So this is using its own network entity?
Aug 31 15:15:16 <cluelessperson>	bozzle  So here's what's happening.    On most configurations you can run docker directly, and this tutorial would result in nginx listening on your computer's localhost at port 80.
Aug 31 15:16:01 <cluelessperson>	Mac/windows are different enough from linux and what docker is based out of, that they make docker work by spinning up a virtual machine in the background.
Aug 31 15:16:24 <cluelessperson>	So docker is run in linux environment in the background (which isn't really anything to worry about)
Aug 31 15:16:49 <cluelessperson>	---
Aug 31 15:17:09 <cluelessperson>	So, all in all.   nginx is running in the virtual machine, listening on localhost:80
Aug 31 15:18:37 <bozzle>	And the virtual machine is sending it somewhere else?
Aug 31 15:19:02 <cluelessperson>	No.  the docker container, nginx, is running there and listening there.
Aug 31 15:19:27 <bozzle>	Then why can't I go to 80 on my machine?
Aug 31 15:19:39 <mgolisch>	because it runs in that vm not your machine
Aug 31 15:20:02 <mgolisch>	you installed docker toolbox but looked at the documentation for docker for osx
Aug 31 15:20:24 <cluelessperson>	bozzle  The VM is acting as a different machine, at the ip address 192.168.99.100, the nginx container is located there.
Aug 31 15:20:27 <bozzle>	Where's the documentation for toolbox?
Aug 31 15:20:53 <cluelessperson>	192.168.99.100 btw, in this case, is only accessible and available to connect to from your machine.
Aug 31 15:20:56 <mgolisch>	its basicaly the same with docker for osx but it does some magic so the published ports are accessible using localhost
Aug 31 15:21:10 <bozzle>	Can the VM act as a different machine at port 80 instead? Is that something that can be done?
Aug 31 15:21:11 <cluelessperson>	yeah, I suspect that magic wasn't happening here.
Aug 31 15:22:11 <cluelessperson>	bozzle     think of addresses as the location, and ports as paths/slots to get there.
Aug 31 15:22:55 <bozzle>	So can I change the address so that I can use port 80 on my machine?
Aug 31 15:23:18 <mgolisch>	no
Aug 31 15:23:26 <mgolisch>	if you want that install docker for osx
Aug 31 15:23:32 <bozzle>	Ok
Aug 31 15:23:40 <cluelessperson>	You can do anything, but it requires some knowledge
Aug 31 15:23:54 <bozzle>	Ah, I see
Aug 31 15:24:05 <cluelessperson>	probably outside your skillset, beyond what I know off the top of my head, and would be a headache.
Aug 31 15:24:07 <bozzle>	I'm doing this so I can use someone else's ... image? from the library they wrote. Would they be able to change the way it's run so it just shows up in `localhost` for macs using Toolbox?
Aug 31 15:24:20 <cluelessperson>	so, I recommend installing docker in way that it handles that for you.
Aug 31 15:24:32 <mgolisch>	bozzle: no it has nothing to do with the image
Aug 31 15:24:36 <bozzle>	I can't, the system I'm using is too old.
Aug 31 15:25:11 <bozzle>	Where's the documentation for Toolbox that would have helped here?
Aug 31 15:26:38 <cluelessperson>	bozzle   You could setup what are called "port forwards", so that when you ask for localhost:22  it's forwarded to  -> 192.168.99.100:22
Aug 31 15:26:40 <mgolisch>	https://docs.docker.com/toolbox/overview/ but not sure it realy meantions alot of helpful stuff
Aug 31 15:26:46 <cluelessperson>	port forwarding anyway
Aug 31 15:27:29 <bozzle>	It doesn't contain anything :/
Aug 31 15:27:52 <bozzle>	Just stuff like the install instructions.
Aug 31 15:28:34 <mgolisch>	i think the getting started guide just asumes you use current stuff
Aug 31 15:30:19 <bozzle>	Yeah
Aug 31 15:32:09 <bozzle>	Now it can't read my CA certificate for some reason :/
Aug 31 15:32:33 <cluelessperson>	bozzle  who's CA certficiate?
Aug 31 15:32:45 <bozzle>	Thanks for solving that mystery, though, cluelessperson. I would never have gotten there otherwise.
Aug 31 15:33:37 <bozzle>	Well shit
Aug 31 15:34:22 <bozzle>	Sorry
Aug 31 15:34:40 <cluelessperson>	bozzle for what?  and what about a CA cert?
Aug 31 15:34:47 <bozzle>	I ran the results of `env` by mistake with some stuff edited. So. Y'know. Restored now.
Aug 31 15:34:53 <bozzle>	Sorry for swearing.
Aug 31 15:35:00 <bozzle>	I don't know what this channel's policies are.
Aug 31 15:35:17 <cluelessperson>	I don't remotely care, but others might
Aug 31 15:39:34 <bozzle>	Anyway, thanks for the assist cluelessperson.
Aug 31 15:42:24 <cluelessperson>	no prob
Aug 31 15:47:47 <bozzle>	Would this be relevant to fixing the issue somehow? https://stackoverflow.com/questions/24319662/from-inside-of-a-docker-container-how-do-i-connect-to-the-localhost-of-the-mach
Aug 31 15:48:27 <bozzle>	Their instructions say other things to do in the terminal. Maybe they could add instructions about this.
Aug 31 15:49:39 <cluelessperson>	bozzle  I'd avoid getting into that detailed stuff.
Aug 31 15:50:12 <bozzle>	Figured I might just link it to them if it was relevant. If they don't want to get into it, that's up to them.
Aug 31 15:57:05 <very_sneaky>	hi all, i'm getting the following error: `Get https://gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)` when i try to push my image to gcr.io. I'm running docker on macos; all the solutions I've come across (mostly for windows) indicate that the proxy settings need to be changed to use google dns; I tried this to no effect. Does anybody know what I need to do to get t
Aug 31 15:57:05 <very_sneaky>	his to work?
Aug 31 16:52:52 <az>	hi, I need help please with this: sudo docker -D build -t askbot:latest --build-arg ASKBOT=. .
Aug 31 16:52:53 <az>	Sending build context to Docker daemon  310.3kB
Aug 31 16:52:53 <az>	Error response from daemon: Error processing tar file(exit status 1): remount /, flags: 0x84000: permission denied
Aug 31 16:53:10 <az>	it's inside LXC
Aug 31 17:59:53 <tabakhase>	az unprivilidged lxc? and where is that dockerD runnin... from memory thats a nada inside lxc...
Aug 31 18:00:59 <tabakhase>	(and unprivi acts like a nsmap with 0 not beeing 0 anymore kinda deal in there)
Aug 31 18:57:39 <Pio>	.4}}45]]]]}46.}46.5]5]5}}}46.]5]].}4}4}]].}4}].].].}}46].
Aug 31 20:06:11 <bozzle>	Does it matter what dir I'm in when I do `docker run`?
Aug 31 20:28:28 <bozzle>	Not sure if this got sent to the channel before: Does it matter what dir I'm in when I do `docker run`?
Aug 31 20:52:54 <lrvick>	So if I run docker-machine with virtualbox backend it mounts my /home as /hosthome inside the VM. In the VM the docker user is uid 1000 gid 50. My container user also is uid 1000 gid 50. I can mount from /hosthome/me/config to /home/build/config in the container. Then things get weird. I can run "git init" in the volume mounted folder and it populates the .git directory as expected. If I try to do a "git add
Aug 31 20:52:55 <lrvick>	." I get: error: insufficient permission for adding an object to repository database .git/objects.
Aug 31 20:53:10 <lrvick>	I can however touch files in .git/objects no problem
Aug 31 20:53:20 <lrvick>	as the container user
Aug 31 21:25:58 <bozzle>	Does it matter what dir I'm in when I do `docker run`? Does it need to be in my HD directly in order to access stuff? Can it just be in a random folder on the desktop?
Aug 31 21:26:24 <lrvick>	Example with strace. This makes no sense: https://gist.github.com/lrvick/8b49f8b40955387bfb7d45da9912e3ba
Aug 31 21:26:25 <bozzle>	Maybe I mean the place where you put `/da`
Aug 31 21:39:33 <tabakhase>	bozzle wherever - cause "run" only takes absolute paths anyways :P
Aug 31 21:40:05 <tabakhase>	now, with docker-compose, what allows "./" - and expands for you before sending it to docker - whole different story :P
Aug 31 21:40:15 <bozzle>	tabakhase: Ok. And thanks. Just wondering if it affects where my server logs are going because I can't find them.
Aug 31 21:40:42 <bozzle>	Thought maybe it couldn't find where to put them.
Aug 31 21:41:27 <tabakhase>	this also makes a bit more sense if you look in what docker actually does under the hood -- there is a deamon running on your system | and any "docker" commands are the CLI using a http api on it todo stuff  ((with the exception of "docker build" where the CLI also does the step of packing the "build context" up))
Aug 31 21:43:13 <tabakhase>	so it "doesnt care about the directory your CLI is running in at all" so to say - cause it may not even be the cli or anything that has a directory at all, as you can totally "call the deamons http-apis with a webbrowser" if you wanted to
Sep 02 08:51:42 *	Disconnected ()
**** ENDING LOGGING AT Mon Sep  2 08:51:42 2019

**** BEGIN LOGGING AT Wed Sep 11 16:33:28 2019

Sep 11 16:33:28 *	Now talking on #docker
Sep 11 16:33:28 *	Topic for #docker is: Docker: Open platform for distributed applications | http://docker.com | Certifications https://success.docker.com/certification | http://github.com/moby/moby | Current Status: http://status.docker.com/ | https://forums.docker.com/ | Registration with NickServ required: https://freenode.net/kb/answer/registration
Sep 11 16:33:28 *	Topic for #docker set by programmerq!~jeff@unaffiliated/programmerq (Fri Dec  7 20:42:52 2018)
Sep 11 16:34:23 <lmat>	Now I changed index.html to index.php. Requesting http://localhost spins. I'm guessing nginx isn't able to talk to my php interpreter.
Sep 11 16:34:57 <lmat>	I guess I should check and see if my php container is listening on 9000 as expected...
Sep 11 16:35:37 <threenuc>	Hi. I'm trying to set up a mysql db for my dev environment. The goal is so other developers working on my project can skip the db config. Is it really not possible to connect to a docker database from my docker host (in this case my personal pc). Ideally it'd be something like `mysql --port=3306 -u root -p`
Sep 11 16:36:02 <lmat>	programmerq: Crap, ss -an; nor nestat -an; works in the container... :-/
Sep 11 16:36:21 <lmat>	threenuc: Of course you can.
Sep 11 16:36:22 <programmerq>	is is possible to connect to a dockerized database. publish the port when you run the container.
Sep 11 16:37:54 <lmat>	programmerq: I switched to *-alpine; (I was on 7-fpm), and netstat is there. it is listening on 9000. Do I need to have a 'ports' section on that service?
Sep 11 16:38:23 <programmerq>	no. a 'ports' section is required for ingress. is nginx telling you that it's seeing a connection refused when connected to your php-fpm container?
Sep 11 16:39:07 <lmat>	timed out
Sep 11 16:39:30 <programmerq>	sounds more like it's communicating with it, but your php code is stuck doing something.
Sep 11 16:39:40 <lmat>	oh, okay... I'll revisit my index.php
Sep 11 16:40:07 <programmerq>	I always start out with a super simple phpinfo() script
Sep 11 16:40:28 <lmat>	programmerq: I was just using the same index.html I had been using   <html><title>...</title><body>...</body></html>
Sep 11 16:40:43 <programmerq>	index.html is 100% handled by nginx and not by php-fpm
Sep 11 16:40:57 <lmat>	programmerq: I    mv index.html index.php;
Sep 11 16:41:07 <lmat>	<?php
Sep 11 16:41:10 <programmerq>	index.php is a php file, and will be handled by php-fpm
Sep 11 16:41:22 <lmat>	echo phpinfo();     is the script they recommend on the tutorial. This shoud end with ?>, right?
Sep 11 16:43:29 <lmat>	client: 172.18.0.1, server: localhost, request: "GET / HTTP/1.1", upstream: "fastcgi://129.79.78.36:9000", host: "localhost"
Sep 11 16:43:32 <lmat>	I'm not sure where it's getting 129...
Sep 11 16:43:49 <programmerq>	what did you put in the nginx config file?
Sep 11 16:44:10 <lmat>	copy and paste.   OOOhhh, mine isn't callet fastcgi_pass_php. doh
Sep 11 16:44:36 <lmat>	I changed the conf. What's the best way to get the service to restart so it will read this conf?
Sep 11 16:45:08 <programmerq>	docker-compose restart <service>
Sep 11 16:45:25 <lmat>	I'm not using docker-compose; I'm using docker swarm/stack/service
Sep 11 16:45:36 <programmerq>	docker service update -f
Sep 11 16:45:48 <lmat>	sweet
Sep 11 16:46:02 <programmerq>	or send that nginx container a HUP
Sep 11 16:47:09 <lmat>	Ahh, docker kill; great idea!
Sep 11 16:48:38 <lmat>	"unknown shorthand flag: 'f' in -f"  u usin some strange magic, boy!?
Sep 11 16:48:51 <lmat>	(The container was down and wasn't goin to restart, so I couldn't send it a signal)
Sep 11 16:49:08 <programmerq>	ah, it's --force
Sep 11 16:49:58 <lmat>	programmerq: I would have expected -f to work, too ^_^. I'm definitely getting somewhere now: FastCGI sent in stderr: "Primary script unknown" while reading response header from upstream
Sep 11 16:50:12 <lmat>	Does the php container need to have the php file?
Sep 11 16:50:26 <lmat>	Is the php container strictly an interpreter? Or will it hold the php code?
Sep 11 16:50:38 <lmat>	threenuc: got it all sorted?
Sep 11 16:56:15 <programmerq>	php-fpm needs to have access to the files.
Sep 11 16:57:02 <programmerq>	that's the kind of weird thing about containerizing this setup- both nginx and php-fpm need to see the same files for this to truly work correctly. nginx will handle serving up static files, but if it sees the file is a php file, it'll pass the request off to php-fpm, which needs access to the file to be able to handle the request.
Sep 11 16:57:34 <programmerq>	so in a prod setup, you'd have to build a new nginx and php-fpm container that has the updated code
Sep 11 16:57:43 <programmerq>	but you'd be able to scale horizontally across arbitrary hosts.
Sep 11 16:59:42 <lmat>	programmerq: I would think the code would be a volume shared with all.
Sep 11 16:59:58 <programmerq>	that pattern breaks down when you want to scale across arbitrary hosts
Sep 11 17:00:12 <programmerq>	plus then you have to not only distribute your docker image artifact, but treat the code repository as an artifact.
Sep 11 17:00:43 <programmerq>	in my opinion, it's simpler just to build one or more images that has the necessary files, and update all the containers in question
Sep 11 17:01:03 <lmat>	programmerq: Seems like I might want to run nginx and php in the same container?
Sep 11 17:01:10 <programmerq>	it's really not that different from tacking on a scheduler/worker process too.
Sep 11 17:01:12 <programmerq>	nah
Sep 11 17:01:18 <programmerq>	just add the code to an nginx image and to the php image
Sep 11 17:01:20 <programmerq>	no big deal
Sep 11 17:01:23 <lmat>	programmerq: If I were using appache PHP (without fpm) I would use only one container.
Sep 11 17:01:34 <programmerq>	correct-- because apache's process model is one process
Sep 11 17:01:38 <programmerq>	nginx and php-fpm are two
Sep 11 17:01:47 <programmerq>	so the way to containerize it reflects that
Sep 11 17:02:10 <lmat>	programmerq: Ah yes, I will still need a reverse proxy anyway.
Sep 11 17:06:01 <threenuc>	@programmerq, thanks, I googled "publish port" and found what I needed. Db is working nice. Thanks
Sep 11 17:06:34 <threenuc>	lmat, yes :) thanks, I just hoped you guys would say a keyword I could google and you did hah
Sep 11 17:08:24 <lmat>	threenuc: nice
Sep 11 17:23:21 <lmat>	programmerq: Okay, I got the way to restart the stack:  docker stack rm mystack; while docker network inspect mystack_default ; do sleep 1; done; docker stack deploy -c mystack.yml mystack;
Sep 11 17:25:27 <lmat>	programmerq: Whoa! Got phpinfo \o/
Sep 11 17:25:33 <lmat>	time to commit
Sep 12 10:08:34 *	Disconnected ()
**** ENDING LOGGING AT Thu Sep 12 10:08:34 2019

**** BEGIN LOGGING AT Thu Sep 12 10:08:58 2019

Sep 12 10:08:58 *	Now talking on #docker
Sep 12 10:08:58 *	Topic for #docker is: Docker: Open platform for distributed applications | http://docker.com | Certifications https://success.docker.com/certification | http://github.com/moby/moby | Current Status: http://status.docker.com/ | https://forums.docker.com/ | Registration with NickServ required: https://freenode.net/kb/answer/registration
Sep 12 10:08:58 *	Topic for #docker set by programmerq!~jeff@unaffiliated/programmerq (Fri Dec  7 20:42:52 2018)
Sep 12 10:13:21 <tsujp>	Can you tag an image from Dockerfile?
Sep 12 10:13:32 <tsujp>	If not, can you get the image ID of the one just built from within the Dockerfile?
Sep 12 11:28:41 <[twisti]>	is there any way to get notifications about upstream changes in the docker repo ? i.e. we have a project based on 'php', and when upstream changes, we need to rebuild our entire image, which takes a long time. that in itself is not a problem, but the problem is that we only NOTICE the change when someone pushes a local change, and the CI server builds the docker image and it suddenly takes 20 times as long as normally
Sep 12 11:29:00 <[twisti]>	it would be neat if we could somehow say "whenever php:latest gets updated, we want our CI server to be noticed"
Sep 12 11:29:10 <Swahili>	Q: After a few attempts found out that the image `wordpress` ( https://hub.docker.com/_/wordpress/ ) does not execute the shell script placed in the entrypoint path, for some reason. I had to create a service with the image `alpine` and a shared dir `/var/www/html` to run the desired script. I don't think this is a good practice though, but it's a solution. How to debug when the entrypoint script does not run? Accessing the cont
Sep 12 11:29:10 <Swahili>	ainer shell, I was able to run manually, I did notice that the sh file does not have read permissions
Sep 12 11:30:24 <cim209>	[twisti]: why don't you just have your images build weekly on a cron job
Sep 12 11:31:35 <[twisti]>	cim209: thats our go-to if we cant find anything better, but that comes with the chance to just miss the upstream change, or a change during the week. notifications would be a neater and cleaner solution
Sep 12 11:31:48 <Swahili>	There's probably images that don't execute the script files in the entrypoint path?!
Sep 12 11:32:03 <[twisti]>	i was thinking maybe there was like a mailing list for new releases that i could use as a trigger for our CI server
Sep 12 11:32:57 <Swahili>	Or, does all images run the script files in entrypoint?
Sep 12 11:34:17 <cim209>	Swahili: all their entrypoints should be executable
Sep 12 11:34:43 <Swahili>	cim209: thanks for looking! right! So, how to debug when the script does not run?
Sep 12 11:35:12 <cim209>	Swahili: run the image in the container but not in -d detach mode
Sep 12 11:36:17 <cim209>	[twisti]: docker php has a github repo
Sep 12 11:36:48 <Swahili>	cim209: I'm using docker-compose and I do `up -d --remove-orphan`, so I should do `up` only to debug?
Sep 12 11:37:08 <cim209>	Swahili: yeah see what outputs in the terminal
Sep 12 11:37:21 <Swahili>	hum ok
Sep 12 11:37:37 <Swahili>	docker-compose, can we just run one image?
Sep 12 11:38:34 <cim209>	docker-compose up service-name
Sep 12 11:39:58 <Swahili>	cim209: cool! I'll try let's see
Sep 12 11:40:14 <[twisti]>	cim209: thanks, ill see if i can use that somehow, i know github supports watching releases now
Sep 12 11:46:28 <Swahili>	if I `echo "Hello world!"` in a script dumped into docker-entrypoint I should see the output right?
Sep 12 11:46:57 <cim209>	did you git clone the repo and build it?
Sep 12 11:47:06 <Swahili>	yeah
Sep 12 11:47:26 <Swahili>	wait, no
Sep 12 11:47:43 <Swahili>	I have it has image: wordpress:latest
Sep 12 11:47:58 <cim209>	[twisti]: maybe you can use this in a cron script https://hub.docker.com/v2/repositories/library/php/tags
Sep 12 11:48:01 <Swahili>	I have it has image: wordpress:php7.3-fpm
Sep 12 11:48:08 <Swahili>	actually
Sep 12 11:48:24 <cim209>	it has "last updated" in a json array
Sep 12 11:48:46 <cim209>	wordpress latest tag is the apache one i think
Sep 12 11:48:56 <cim209>	or none alpine
Sep 12 11:48:58 <Swahili>	yeah sorry, using php7.3-fpm
Sep 12 11:49:28 <Swahili>	so, not sure why the script is not exec
Sep 12 11:50:00 <Swahili>	I'll down, stop, remove all volumes, networks, etc and try again from scratch and see if that helps
Sep 12 11:50:05 <Swahili>	did try it last night without success
Sep 12 11:50:08 <Swahili>	will do once again
Sep 12 11:50:40 <cim209>	i opened a shell to that image and it does work
Sep 12 11:51:09 <cim209>	that entrypoint needs the first variable to be php-fpm
Sep 12 11:51:51 <Swahili>	cim209: this is part of my docker-compose if you don't mind have a quick look https://paste.ee/p/BcYJp#15fWobm8lqE13ui9iaUOxUwAkfg9Ku96
Sep 12 11:52:26 <Swahili>	at the moment the script content is just #!/bin/sh \ echo "HELLO WORLD!"
Sep 12 11:53:11 <[twisti]>	cim209: id rather not hammer a public, free service with a cron job, even if itll be a low frequency hammer. i think the github solution is best, since they push notification
Sep 12 11:53:24 <[twisti]>	but thank you anyways
Sep 12 11:53:44 <cim209>	that's why you set the cron job to hourly or something
Sep 12 11:53:47 <Swahili>	and the log https://paste.ee/p/JJTpl#0iuk1CXuZrCZC4mBDeaqAZzrI5xCnkTs
Sep 12 11:53:51 <cim209>	or daily
Sep 12 11:53:59 <Swahili>	wordpress    | [12-Sep-2019 09:52:43] NOTICE: ready to handle connections
Sep 12 11:54:08 <cim209>	Swahili: looks like it's working like it should
Sep 12 11:54:12 <Swahili>	so it does not show "Hello world", if I'm supposed to see that
Sep 12 11:54:20 <cim209>	what is the problem?
Sep 12 11:54:51 <Swahili>	cim209: the problem is that I'm supposed to see the "hello world" right?
Sep 12 11:55:27 <Swahili>	the script content atm https://paste.ee/p/Bdcm2#4iZ65MXXI1pfSWfTbPs06SVBEmC237Nx
Sep 12 11:55:44 <cim209>	are you trying to override the entrypoint in a dockerfile or during run time?
Sep 12 11:56:09 <cim209>	i'm not sure what you're trying to do here
Sep 12 11:57:39 <Swahili>	cim209: I'd like to run a script when the image is built. The wordpress image comes with the wordpress files but I need to modify .htaccess etc.
Sep 12 11:59:34 *	Disconnected ()
**** ENDING LOGGING AT Thu Sep 12 11:59:34 2019

**** BEGIN LOGGING AT Thu Sep 12 11:59:57 2019

Sep 12 11:59:57 *	Now talking on #docker
Sep 12 11:59:57 *	Topic for #docker is: Docker: Open platform for distributed applications | http://docker.com | Certifications https://success.docker.com/certification | http://github.com/moby/moby | Current Status: http://status.docker.com/ | https://forums.docker.com/ | Registration with NickServ required: https://freenode.net/kb/answer/registration
Sep 12 11:59:57 *	Topic for #docker set by programmerq!~jeff@unaffiliated/programmerq (Fri Dec  7 20:42:52 2018)
Sep 12 11:59:58 <artok>	to run any script on image building, COPY it and then RUN
Sep 12 12:01:52 <Swahili>	oh ok
Sep 12 12:02:23 <cim209>	i thought you knew that Swahili
Sep 12 12:02:24 <Swahili>	so, create a Dockerfile FROM wordpress:php7.3-fpm, and then COPY script and then RUN ?
Sep 12 12:02:49 <artok>	yeah
Sep 12 12:03:02 <Swahili>	cim209: no, I thought I could use the entrypoint differently
Sep 12 12:03:03 <artok>	that will be then done when build happens
Sep 12 12:03:19 <Swahili>	Ok, I'll do that!
Sep 12 12:04:29 <Swahili>	So, for the wordpress image, it provides all the wordpress source files in /var/www/html; If I do COPY and then RUN, will this happen after the files are placed there etc, or I should put a sleep or wait for file availability in the script before the command is run?
Sep 12 12:06:35 <artok>	what exactly are doing? and commands are run in serial, so there is no need for wait
Sep 12 12:08:51 <Swahili>	artok: yeh, so I'll modify some of the files provided by the image; that is the wordpress source files.
Sep 12 12:08:57 <Swahili>	I'll TIAS
Sep 12 13:23:03 <threenuc>	Hi. I'm trying to use the mysql:8 image but it turns out that I need to modify it more and more on startup, so I decided to use a Dockerfile (never used it before). So I do `FROM mysql:8` assuming it will use the mysql v8.0 image. Then i write `RUN mysql -u root -proot < db.sql` I get errors that are explained in a way that 'well the mysql service is not running'
Sep 12 13:23:44 <threenuc>	But if I do docker run -d mysql:8, the container comes online with mysql working. Will using FROM not start my Dockerfile at the end of the mysql:8 Dockerfile?
Sep 12 13:24:09 <threenuc>	Like, if the mysql:8 Dockerfile starts the mysql service, why doesn't it start it when I use FROM mysql:8?
Sep 12 15:06:41 <programmerq>	threenuc▸ when you do a RUN statement, the command you pass in is the *only thing running* in that layer. The mysql image declares /var/lib/mysql as a volume, so even if mysql was running and that command worked, it'd import to an anonymous volume that would be discarded at the end of the RUN step. Instead,
Sep 12 15:07:20 <programmerq>	you can take advantage of the features listed under the "Initializing a fresh instance" header here: https://hub.docker.com/_/mysql
Sep 12 15:07:41 <programmerq>	basically, the entrypoint script for that image looks in a specific location for .sql and/or .sh files and runs them the first time the container comes up.
Sep 12 15:19:54 <Swahili>	Q: In docker-compose if we mount a host dir to a container path we can share between services; if we build the image separately and happens that the images provides some application source files in a particular path, how to share between services?
Sep 12 15:29:45 <programmerq>	Swahili▸ make both services use a common image, or ADD/COPY the same source to the image for both.
Sep 12 15:29:56 <programmerq>	having a web server and a background worker, for example
Sep 12 15:30:17 <programmerq>	both those services could use the same image that has the same source in it, and only differ in the command that is run
Sep 12 15:30:54 <programmerq>	but if you're needing the source for highly different components (nginx and php-fpm, for example), then ADD/COPY the source to both images you use
Sep 12 15:31:47 <Swahili>	programmerq: thanks for looking!
Sep 12 15:33:34 <Swahili>	Ok, so I have a wordpress:php-fpm image; but also a worker service that is composer/composer; before I had `volumes:  - hostApplicationSource:applicationPath`
Sep 12 15:34:23 <Swahili>	then I had to create a Dockerfile for the wordpress:php-fpm, and removed the volume in the docker-compose declaration
Sep 12 15:34:59 <adhawkins>	Can a docker container started with docker-compose be on more than one network?
Sep 12 15:35:25 <Swahili>	to let both services use the same sourcePath:destinationPath, I just need to make sure the source is the same in the Dockerfiles; is that it programmerq?
Sep 12 15:35:58 <programmerq>	adhawkins▸ yes.
Sep 12 15:36:41 <adhawkins>	programmerq: Would it get multiple network interfaces in order for this to work then?
Sep 12 15:37:23 <programmerq>	Swahili▸ for production, you'll skip the bind mounts and use the copy of the source in the image-- so that means that the Dockerfile should ADD/COPY the source for each image. If you're doing local development, then you can keep the same Dockerfile, and add in the bind mount over top of the copy of the source in the image.
Sep 12 15:37:34 <programmerq>	adhawkins▸ yes.
Sep 12 15:37:58 <adhawkins>	Looking to have multiple docker-compose files starting up various services, then a final docker-compose that fires up nginx to work as an https proxy for those other services. Wondering if this would 'just work' if I connected up the nginx container to the networks defined in the other docker-compose files?
Sep 12 15:38:31 <programmerq>	in the compose world, you'd declare it as an "external" network.
Sep 12 15:39:03 <programmerq>	although, I'd recommend doing it backwards. bring up your proxy first, and then define an external network in all your other compose files, and only attach the service you need to be proxied to the proxy network.
Sep 12 15:39:45 <adhawkins>	programmerq: But those external services would probably end up being on two networks (as some of them have an internal network they use to communicate between VMs in that docker-compose file)
Sep 12 15:39:56 <programmerq>	adhawkins▸ yup, and that's just fine.
Sep 12 15:40:26 <adhawkins>	Ok, just wondering. Will have a play with that then. Thanks for the advice.
Sep 12 15:40:45 <adhawkins>	Anything special needed for DNS lookups to work in the nginx container allowing it to see the other containers by name?
Sep 12 15:40:56 <programmerq>	no
Sep 12 15:41:02 <programmerq>	well, kind of
Sep 12 15:41:19 <programmerq>	nginx out of the box doesn't look at /etc/resolv.conf so you have to explicitly set the 127.0.0.11 resolver
Sep 12 15:45:36 <slavanap>	Hi! Is there a custom network driver to limit container to talk to specific list of IPs only (restrict outgoing internet traffic)?
Sep 12 15:48:30 <adhawkins>	programmerq: The container I'm using seems to work correctly (linuxserver.io)
Sep 12 15:49:39 <adhawkins>	Currently the nginx container is started in the same docker-compose file as the others. It can see the others by using container names as hostnames.
Sep 12 15:51:07 <adhawkins>	Presumably there'll be a startup order issue, if I tell docker-compose to create a container using an external network that hasn't been created yet?
Sep 12 15:51:39 <adhawkins>	Will have to try to find out (when using 'restart: unless-stopped' if there's a way to force the nginx container to start up before the others.
Sep 12 15:53:18 <programmerq>	slavanap▸ no, there isn't anything like that out of the box that I'm aware of.
Sep 12 15:53:30 <programmerq>	slavanap▸ what sort of traffic? tcp/udp? https? something else?
Sep 12 15:53:46 <programmerq>	is this egress traffic going to other hosts, or other containerized services?
Sep 12 15:54:25 <slavanap>	I want to experiment with part of production from inside docker container, and in order to not break something real, I need a way to isolate outgoing traffic to everything else except my host computer.
Sep 12 15:54:26 <programmerq>	adhawkins▸ the external network must already exist, or docker-compose will exit with an error.
Sep 12 15:54:44 <programmerq>	adhawkins▸ that's why I suggest doing the proxy first-- that way you don't have to bring up all your projects and *then* the proxy
Sep 12 15:55:26 <programmerq>	slavanap▸ connect that container to a network that was created with --internal, and use that network's gateway ip to talk to the host.
Sep 12 15:56:29 <slavanap>	programmerq, I've never heard of internal networks. Thanks. I'll google it
Sep 12 15:58:22 <programmerq>	the other thing you can do is bring up a container with --cap-add net_admin, set some iptables rules to do what you want within the container, and then bring up your real container with --net container:<othercontainerwithmodifiedrules>
Sep 12 15:59:22 <slavanap>	Thanks you very much!
Sep 12 16:40:30 <SpeakerToMeat>	I can't find otu what I'm doing wrong for my volumes section on my docker compose file.... https://hastebin.com/ebiyomipiy.bash
Sep 12 16:40:47 <SpeakerToMeat>	It looks identical to the web page sample
Sep 12 16:45:22 <Swahili>	I had a worker service (image `composer/composer`), that I've now removed and now RUN curl command to get composer and link the binary to global and install a package phpdotenv. While conceptually this should work, I thought, the RUN commands while I can see in the log, the composer packages are now installed, neither the composer bin
Sep 12 16:45:29 <Swahili>	Here's the Dockerfile https://paste.ubuntu.com/p/vJwt2rkDzF/
Sep 12 16:46:06 <Swahili>	basically doing
Sep 12 16:46:07 <Swahili>	RUN curl -sS https://getcomposer.org/installer | php -- --install-dir=/usr/bin --filename=composer && chmod +x /usr/bin/composer
Sep 12 16:46:13 <Swahili>	followed by
Sep 12 16:46:14 <Swahili>	RUN composer require vlucas/phpdotenv
Sep 12 16:49:09 <tabakhase>	Swahili wordpress is "special"...  /var/www/html is a volume that gets poped by the entrypoint on first run
Sep 12 16:49:31 <Swahili>	tabakhase: thanks for looking! yeah, so that's what I'm trying to solve
Sep 12 16:49:45 <tabakhase>	(thats also why ${WORDPRESS_VERSION} is kinda "Not a thing" there, as updating the WP itself is NOT done "by docker" later on...
Sep 12 16:50:14 <Swahili>	tabakhase: yeah, so what solutions do I have? before I had the worker composer/composer and worked great
Sep 12 16:50:39 <Swahili>	but now without a shared volume decided to add composer in the wordpress builder
Sep 12 16:52:43 <tabakhase>	mess with /usr/src/wordpress id guess...
Sep 12 16:53:46 <Swahili>	so the RUN commands happen before the entrypoint ?
Sep 12 16:54:16 <Swahili>	I'll also try the /usr/src/wordpress
Sep 12 16:58:47 <Swahili>	tabakhase: where did you find about /usr/src/wordpress ?
Sep 12 16:58:56 <Swahili>	is that documented or you just looked around
Sep 12 17:00:07 <tabakhase>	https://github.com/docker-library/wordpress/blob/cca618c2e6c1414859162d6f1316652daa8515f7/php7.1/apache/Dockerfile#L65 && https://github.com/docker-library/wordpress/blob/cca618c2e6c1414859162d6f1316652daa8515f7/php7.1/apache/docker-entrypoint.sh#L48
Sep 12 17:01:44 <Swahili>	tabakhase: thanks! So the best documentation is to look into the original Dockerfile's and the entrypoint scripts
Sep 12 17:01:50 <Swahili>	that's what you people do right?
Sep 12 17:02:10 <tabakhase>	thats the very first thing if you want to mod anything yea...
Sep 12 17:04:04 <Swahili>	Ok cool! Thanks for sharing the knowledge
Sep 12 17:04:08 <Swahili>	That's very helpful!
Sep 12 17:04:19 <Swahili>	Saved me a lot of time
Sep 12 17:14:27 <Swahili>	Interesting now, because for the `wordpress:php-fpm`, I have a nginx reverse proxy and I need to mount the volume
Sep 12 17:14:30 <Swahili>	how to solve that?
Sep 12 17:16:35 <Swahili>	I'll mount the same host path to the container path and see what happens. Because I've solved the composer issue before by changing it in the source `/usr/src/wordpress`
Sep 12 17:17:51 <Swahili>	`WARNING: Service "wordpress" is using volume "/var/www/html" from the previous container. Host mapping "/Users/punkbit/www/moola-starter-blog-cms/.docker/wordpress/src" has no effect. Remove the existin`
Sep 12 17:26:21 <asgardian>	hello
Sep 12 17:28:35 <asgardian>	I have a question regarding docker-compose when a volume is declared what is the difference between "volume_name: {}" and "volume_name:" what "{}" stands for?
Sep 12 17:33:31 <ada>	nothing
Sep 12 17:34:56 <ada>	asgardian: where are you seeing this example?
Sep 12 17:35:33 <ada>	https://docs.docker.com/compose/compose-file/#name
Sep 12 17:35:36 <asgardian>	on linuxacademy docker deep dive course :)
Sep 12 17:35:44 <ada>	linuxacademy needs to update thier course material
Sep 12 17:35:55 <asgardian>	oh, ok
Sep 12 17:36:08 <adhawkins>	If I want a container created using docker-compose to be on both the 'default' network created for the compose file, *and* one listed as an external network, do I need to list both in the 'networks' section for each container? If so, will 'default' work as a name, or do I have to give it the full name (composefile_default)?
Sep 12 17:38:00 <asgardian>	thank you ada
Sep 12 17:38:40 <ada>	adhawkins: under the services: key, you are assigning a network to a service
Sep 12 17:38:49 <ada>	adhawkins: in the top-level networks: key, you define each network
Sep 12 17:38:56 <Swahili>	For the problem that I've exposed about, seems that is best to forget about the official wordpress image and stick with my own, to solve the shared volume issue; As I need it to have the reverse-proxy for PHP-FPM to work. Let me know if there are any alternatives, thank you!
Sep 12 17:39:07 <ada>	adhawkins: so under the top-level networks key you can set the name of your network, but in the services: key it's just a key->value pair
Sep 12 17:39:14 <ada>	adhawkins: making an example
Sep 12 17:39:47 <ada>	adhawkins: https://gist.github.com/adamancini/39fc34f50a5be5c419f3e1e1047420b6
Sep 12 17:40:41 <ada>	if I have a service:  key without a networks: key, it is going to be attached to the 'default' network for that stack
Sep 12 17:41:55 <ada>	updated
Sep 12 17:42:14 <adhawkins>	Thanks ada, just what I wanted.
Sep 12 17:42:39 <ada>	sure thing
Sep 12 17:43:54 <adhawkins>	Could I omit the 'default' section completely from the top level networks section? And it'd just create on with the 'file_default' name style?
Sep 12 17:44:03 <ada>	yes
Sep 12 17:44:26 <biam>	hi all, i'm having some trouble with regular expressions in my Dockerfile that i'm hoping someone can help me with.
Sep 12 17:44:41 <biam>	https://www.irccloud.com/pastebin/1Lwj1LzF/
Sep 12 17:45:30 <biam>	including the regex causes the following error: /bin/sh: [clamscan,: not found
Sep 12 17:46:09 <biam>	any ideas how to fix this?
Sep 12 17:46:24 <ada>	"including the regex" does that imply taking it out works as expected?
Sep 12 17:46:30 <biam>	yes
Sep 12 17:46:32 <ada>	can you show both examples
Sep 12 17:46:34 <ada>	in the same pastebin
Sep 12 17:46:47 <ada>	just as a point of comparison
Sep 12 17:46:51 <biam>	sure
Sep 12 17:47:38 <biam>	https://www.irccloud.com/pastebin/pHYF8MjN/
Sep 12 17:55:35 <tabakhase>	id guess that $ gets "lost"
Sep 12 17:56:29 <abyx>	how can i create and drop into a temporary container for testing things?
Sep 12 17:57:04 <tabakhase>	abyx run & exec?
Sep 12 17:57:24 <ada>	docker run -it busybox
Sep 12 17:57:33 <tabakhase>	may want to overwrite --entrypoint "" - and use "sh/bash" as cmd/ 1st arg in run
Sep 12 17:57:38 <ada>	depends
Sep 12 17:57:42 <ada>	might not matter
Sep 12 18:15:40 <Imaginatrix>	If I add a service in a docker compose file and give it a named volume, if I do not declare a volume a the top-level of my docker compose yaml file will it just look for existing volumes?
Sep 12 18:16:51 <Imaginatrix>	And further, if I DO provide a top-level named volume in my yaml file, if I run it the first time it creates the volume, and the second time it just uses the one that was previously created? Or does it recreate it all over again?
Sep 12 18:17:39 <programmerq>	docker-compose fights to reuse existing volumes-- whether named or anonymous.
Sep 12 18:20:13 <Imaginatrix>	so should i create my named volumes, like an nfs "gitlab-data" volume, externally (as in not in my docker-compose.yaml file) through the command line and then in my docker-compose just not put a top-level volume declaration and just do service: gitlab: volume: gitlab-data:/var/opt/gitlab?
Sep 12 18:21:26 <programmerq>	if you want to create it outside compose, you still need to declare it in the top level volumes in the compose file, but mark it as external.
Sep 12 18:21:41 <programmerq>	What problem are you hoping to solve by having compose not create it for you?
Sep 12 18:25:14 <Imaginatrix>	im fine having compose create it i just don't want it to be recreating it everytime i need to run my config file and have it mess data up
Sep 12 18:25:46 <Imaginatrix>	so like if i have it declared in the file, it should just create it, and then use the existing one on the 2nd run forwards
Sep 12 18:26:08 <Imaginatrix>	thank you for your help btw
Sep 12 18:26:08 <programmerq>	that's the behavior that compose has.
Sep 12 18:26:24 <programmerq>	you basically have to explicitly delete it (docker-compose down)
Sep 12 18:26:35 <programmerq>	just running docker-compose up  again won't delete volumes.
Sep 12 18:27:10 <Imaginatrix>	so it doesn't delete it, it creates twp volumes?
Sep 12 18:27:24 <programmerq>	it'll reuse it
Sep 12 18:27:33 <Imaginatrix>	like each time i run compose its going to keep making copies of my volumes?
Sep 12 18:27:36 <programmerq>	...
Sep 12 18:27:45 <Imaginatrix>	that's what i was getting at
Sep 12 18:27:49 <programmerq>	whip up an example file and try it out
Sep 12 18:27:55 <Imaginatrix>	so if it's reusing it, how do you mean its recreating it?
Sep 12 18:28:00 <Imaginatrix>	you are saying its doin gboth
Sep 12 18:28:02 <Imaginatrix>	doing both*
Sep 12 18:28:13 <programmerq>	reusing means to use an existing thing
Sep 12 18:28:17 <programmerq>	recreating would be making a new thing
Sep 12 18:28:46 <Imaginatrix>	yeah but you said it recreates it and you just said it would reuse it, like if i spin up a standard docker command
Sep 12 18:29:19 <programmerq>	I don't see the word "recreate" in any of my messages.
Sep 12 18:30:45 <Imaginatrix>	no need to be pedantic lol. you didnt state it explicitly but you said that docker fights to reuse existing volumes. and then when i asked about it recreating them you said that was the behavior compose has
Sep 12 18:31:09 <disi>	when multiple FROMs are stacked like this, do they share the COPYs/etc below? https://github.com/docker/compose/blob/d7c7e21921fba349f2fc2fa702c07d87166d80c9/Dockerfile#L67
Sep 12 18:31:28 <programmerq>	https://gist.github.com/programmerq/8b9ee09cc094406241f1c44d6a51953d
Sep 12 18:31:44 <programmerq>	you very clearly said you want compose to reuse and not recreate, and I said "that is the behavior compose has"
Sep 12 18:31:46 <programmerq>	...
Sep 12 18:31:50 <programmerq>	try it for yourself
Sep 12 18:32:08 <Imaginatrix>	ok
Sep 12 18:32:20 <Imaginatrix>	thanks
Sep 12 18:53:36 *	Disconnected ()
**** ENDING LOGGING AT Thu Sep 12 18:53:36 2019

**** BEGIN LOGGING AT Thu Sep 12 18:54:02 2019

Sep 12 18:54:02 *	Now talking on #docker
Sep 12 18:54:02 *	Topic for #docker is: Docker: Open platform for distributed applications | http://docker.com | Certifications https://success.docker.com/certification | http://github.com/moby/moby | Current Status: http://status.docker.com/ | https://forums.docker.com/ | Registration with NickServ required: https://freenode.net/kb/answer/registration
Sep 12 18:54:02 *	Topic for #docker set by programmerq!~jeff@unaffiliated/programmerq (Fri Dec  7 20:42:52 2018)
Sep 12 18:54:08 <programmerq>	look at the networks you are on and the routes you have.
Sep 12 18:56:34 <helo>	ahh, it's related to a messy cleanup job, where we docker stop; rm -rf /var/lib/docker/*; docker start, and it's leaving the routes
Sep 12 18:58:30 <programmerq>	oh goodness
Sep 12 18:58:44 <programmerq>	you stop containers, leave the daemon running, and then delete /var/lib/docker/* ?
Sep 12 18:58:55 <helo>	no, sto pthe dameon, rm, then start daemon
Sep 12 18:58:57 <programmerq>	or are you actually stopping and starting docker itself?
Sep 12 18:59:06 <programmerq>	that honestly sounds like it shouldn't be an issue
Sep 12 18:59:15 <programmerq>	what version of docker are you running?
Sep 12 18:59:30 <programmerq>	I *believe* it should remove the routes when it comes down-- if you allow it to do so cleanly.
Sep 12 19:01:48 <disi>	is there a way to put CMD in the first stage of a multi-stage build?
Sep 12 19:05:45 <Swahili>	I've moved some commands to a dockerfile instead, but it's not running and skips to the last step it seems that is npm install, but some packages fail, as it doesn't exist yet unless apt-get runs
Sep 12 19:05:48 <Swahili>	https://paste.ee/p/MFfBT#2LFMeG05715oHL30LekZ8g2d0aHLhtKH
Sep 12 19:06:49 <ada>	disi: no, CMD is only executed when your container actually runs;  during multi-stage, only the contents of the final stage are made into the image
Sep 12 19:07:05 <disi>	ada: ok, ty
Sep 12 19:07:17 <helo>	programmerq: hmm, looks like it doesn't remove them, maybe because 18.06.1-ce
Sep 12 19:07:43 <disi>	what is the point of stacking FROMs like this? https://github.com/docker/compose/blob/d7c7e21921fba349f2fc2fa702c07d87166d80c9/Dockerfile#L67
Sep 12 19:21:09 <Swahili>	a service that has build + context + dockerfile, if I want to reuse the same image, in a worker or slave service, I should place the build + content + dockerfile ?
Sep 12 19:22:53 <programmerq>	disi▸ it looks like those FROMs were put there and then never actually utilized, so they're basically a no-op. in theory, one could do a COPY --from=runtime to grab a file from that image/build stage and then place it in the final stage.
Sep 12 19:23:16 <programmerq>	runtime-alpine and runtime-debian appear to be unused, but the line you specifically linked (line 67) is the final stage
Sep 12 19:23:27 <rolandas>	hello i cant get it i have docker-compose file and volumes:
Sep 12 19:23:27 <rolandas>	      - db-volume:/var/lib/psql this line does data is stored locally not in container?
Sep 12 19:23:29 <programmerq>	and it copies stuff from the build context, then docker-cli, then build stages.
Sep 12 19:23:57 <disi>	huh, interesting, ok, ty
Sep 12 19:24:12 <programmerq>	rolandas▸ a volume is a directory on your docker host that is bind mounted into the container. This allows your container to be swapped out (like when you want to use a newer image, for example) but you want to keep your persistent data around.
Sep 12 19:24:27 <programmerq>	the container still sees it, but it isn't on that container's write layer, which is ephemeral
Sep 12 19:24:53 <disi>	is there a way to loop in docker with different images? my first stage builds a binary, and i try running the binary with a bunch of different base images (same steps to copy from build and run). i'm hoping to dedupe the copy and run steps for those images
Sep 12 19:25:34 <rolandas>	programmerq: but where does this data stored in volumes?
Sep 12 19:25:49 <programmerq>	no, there's no looping logic in the Dockerfile syntax. at that point, I'd recommend using a bash script in conjunction with build args to do looping logic
Sep 12 19:26:07 <programmerq>	rolandas▸ named and anonymous volumes are by default stored under /var/lib/docker/volumes on the docker host in question.
Sep 12 19:26:10 <disi>	ok, ty
Sep 12 19:26:26 <Swahili>	* about my question above, it seems to work, but I'm not sure if the build is running twice because I can see in the logs all the steps for both services?!
Sep 12 19:27:17 <programmerq>	Swahili▸ if you tell docker-compose to do two builds, it will do two builds. You can override the image name to be the same thing between both services, and only specify the build for one of them. I've had some success with that approach.
Sep 12 19:27:29 <rolandas>	programmerq: if i am deleting container i am not losing data yes?
Sep 12 19:27:44 <SpeakerToMeat>	Docker trivia of the day: If you're basing yourself on a deb based image, always run apt-get update on the same run command as apt-get install commands.
Sep 12 19:28:10 <programmerq>	rolandas▸ correct. the volume is a separate entity and won't be deleted unless specifically specified.
Sep 12 19:28:23 <SpeakerToMeat>	The way I do it is: RUN apt-get update && apt-get install -y .....
Sep 12 19:29:03 <programmerq>	SpeakerToMeat▸ run cleanup commands too and you'll get a slightly smaller image too.
Sep 12 19:29:17 <Swahili>	programmerq: thanks for looking! Yeh, my first attempt, the master service I've set a container_name: foobar that is the same name as the service; now...for the slave service, I tried to place the master container_name in the image: foobar; need to find out how to override the image to be the same between both services
Sep 12 19:29:23 <SpeakerToMeat>	programmerq: Good advice
Sep 12 19:29:31 <Swahili>	in case someone know or have an example, please let me know : ) thank you!
Sep 12 19:29:41 <programmerq>	Swahili▸ container_name is not the same thing as image
Sep 12 19:29:57 <rolandas>	programmerq: is there a way to check content of volume?
Sep 12 19:30:02 <Swahili>	yeah...was just trying as I don't know how to do it yet, searchinv
Sep 12 19:30:05 <Swahili>	searching.
Sep 12 19:30:14 <programmerq>	https://github.com/programmerq/scaletest/blob/master/docker-compose.yml - here's how to specify an image name.
Sep 12 19:30:44 <SpeakerToMeat>	rolandas: An easy way is to create a small container like a busybox one, and mount the volume to it to check it out
Sep 12 19:31:30 <programmerq>	yeah-- just attach a container to it and look at it that way. if you are on the host, you could also see it by going to /var/lib/docker/volumes/<name>/_data/
Sep 12 19:31:46 <programmerq>	but going in that way isn't really a guaranteed thing that should be scripted around
Sep 12 19:31:58 <rolandas>	ok cool
Sep 12 19:32:19 <SpeakerToMeat>	rolandas: Be aware more than one container can use a named volume, either at the same time, or different times
Sep 12 19:32:20 <Swahili>	programmerq: yeah thanks! but in my case I'm using docker-compose and the dockerfile for the image https://paste.ee/p/s60fT#pFXHTHJr5ssSwuvCi90CLc33gtlcfuil
Sep 12 19:32:35 <rolandas>	thanks
Sep 12 19:32:37 <Swahili>	I'll try to add the image: foobar and see what happens
Sep 12 19:33:05 <SpeakerToMeat>	Be specially aware of it if you design a volume to be used by several containers so you don't have race or concurrency problems if the data is shared
Sep 12 19:33:15 <programmerq>	yup, just like any folder on a linux system, one or more process can see and access it. (containers are just a fancy way to run a process).
Sep 12 19:34:06 <SpeakerToMeat>	rolandas: Also, somethign that can be usefull, the first time you create a named volume, if the mountpoint on the container that uses it (first) is not empty, the contents of the mountpoitn wil be copied to the newly created volume
Sep 12 19:34:11 <programmerq>	Swahili▸ the docker-compose.yml file I linked is a docker-compose file, and there's a Dockerfile associated with it. I've just used the short syntax for the build.
Sep 12 19:34:32 <programmerq>	so that difference really isn't a concern
Sep 12 19:34:39 <programmerq>	so you'd remove the build key for the second service
Sep 12 19:34:46 <programmerq>	and add an image: key for both services, and have it be the same image
Sep 12 19:34:50 <programmerq>	that's it
Sep 12 19:34:52 <Swahili>	programmerq: ahhh ok interesting, that's nice
Sep 12 19:34:52 <SpeakerToMeat>	programmerq: I finally gave up, and created a docker-compose-dev.yml :)
Sep 12 19:35:18 <SpeakerToMeat>	programmerq: It has the upside of letting me leave a version tagged on my deploy yml file and use :latest on the dev one
Sep 12 19:35:20 <cronolio>	i can't setup efk https://hastebin.com/tofinukuma.bash from article https://docs.fluentd.org/v/0.12/articles/docker-logging-efk-compose
Sep 12 19:35:42 <Swahili>	what's the image: programmerq/scaletest:TERM_HERE ? that's the difference for both services, is that a tag?
Sep 12 19:35:56 <cronolio>	after this docker don't work at all and can only be rebooted
Sep 12 19:35:59 <programmerq>	yeah, it's a tag
Sep 12 19:36:08 <programmerq>	in my example, that is two separate images
Sep 12 19:36:16 <programmerq>	I've shown it to show you how to set the image name
Sep 12 19:37:56 <Swahili>	programmerq: Ok cool! foobar/foobar:a != foobar/foobar:b
Sep 12 19:38:10 <Swahili>	but foobar/foobar == foobar/foobar
Sep 12 19:38:23 <programmerq>	yup
Sep 12 19:38:35 <programmerq>	and any time you leave off a tag, :latest is implicitly present.
Sep 12 19:38:38 <SpeakerToMeat>	foobar/foobar is equivalent (afaik) to foobar/foobar:latest as well
Sep 12 19:39:23 <Swahili>	That's cool! Thank you so much!
Sep 12 19:51:45 <rolandas>	how can i create user and database for psql in docker?
Sep 12 19:54:00 <NOTevil>	rolandas: the environment variables will do it.  https://hub.docker.com/_/postgres  or you can load init data with /docker-entrypoint-initdb.d/*.sql files.
Sep 12 19:54:22 <NOTevil>	or shell scripts *.sh.
Sep 12 19:56:34 <helo>	thanks programmerq, really appreciate your time!
Sep 12 19:58:48 <rolandas>	NOTevil: i fallowed instruction but new user nor new db is created what is wrong https://github.com/Rolandas1369/psqldocker/tree/master/jiraapp ?
Sep 12 20:02:00 <tabakhase>	rolandas youre not doing anything with docker-entrypoint-initdb.d
Sep 12 20:02:28 <rolandas>	tabakhase: do i need specify entrypoint in dockerfile?
Sep 12 20:02:57 <rolandas>	or something in docker compose?
Sep 12 20:03:02 <tabakhase>	that dockerfile is your app, not your db
Sep 12 20:04:22 <tabakhase>	(also that image offers POSTGRES_USER & POSTGRES_DB to use already...)
Sep 12 20:04:56 <tabakhase>	and last, make sure youre not having a "older attempt" volume still sticking around, that init obvs. only runs on the "very very first start"
Sep 12 20:06:08 <rolandas>	hmm i need to add POSTGRES_USER & POSTGRES_DB to docker-compose?
Sep 12 20:06:31 <tabakhase>	you need to read the readme ;-)
Sep 12 20:06:42 <rolandas>	:D
Sep 12 20:06:47 <rolandas>	where?
Sep 12 20:06:48 <SpeakerToMeat>	If anybody here develops in flask: Right now I'm using development FLASK_ENV=development so any html templates I change I can see immediately... but whenever I change code, I need to stop and restart the containers (I am mounting the app dir inside the container to avoid havign to rebuild)... is there any easier way to have uwsgi or supervisor or someone reload the app when any code file changes?
Sep 12 20:06:54 <Swahili>	I usually find empty files when I copy dot files, like .npmrc or .env, the container has the file, but empty. Usually dot files are ignored, not sure it it's the case. Does anyone know the expectation here?
Sep 12 20:07:25 <programmerq>	SpeakerToMeat▸ there are python code reloaders out there
Sep 12 20:07:34 <NOTevil>	in docker-compose (after line 10) add:   - ./jiraapp/docker-entrypoint-initdb.d/init-user-db.sh:/docker-entrypoint-initdb.d/init-user-db.sh
Sep 12 20:08:25 <Swahili>	Also, do .env variables pass to Dockerfiles if we have it in the docker-compose? Nope right?
Sep 12 20:08:26 <programmerq>	SpeakerToMeat▸ keep in mind that if you're sharing code into a VM from your workstation, then it may not support inotify.
Sep 12 20:09:20 <rolandas>	NOTevil: ty
Sep 12 20:09:31 <programmerq>	Swahili▸ if you want to paramatarize a Dockerfile, then you need to use build args. if you pass in a .env file to a service in compose, that's applied at runtime, and not to the build step.
Sep 12 20:10:04 <Swahili>	programmerq: Cool! Thanks for helping out!
Sep 12 20:10:50 <NOTevil>	rolandas: that maps the script into the /docker-entrypiont-initdb.d directory of the postgres container.
Sep 12 20:11:17 <rolandas>	NOTevil: yes this part is clear :)
Sep 12 20:13:01 <programmerq>	SpeakerToMeat▸ https://flask.palletsprojects.com/en/1.1.x/server/ - if you are doing 'flask run' with FLASK_ENV=development, in theory it should pick it up. if you're not using 'flask run' then you'd have to devise your own reload appropriate for that server.
Sep 12 20:13:31 <NOTevil>	rolandas: you might need to `docker-compose down -v` to remove the volumes, then up will redo the db initialization part.
Sep 12 20:13:43 <SpeakerToMeat>	programmerq: Yeah, even on my dev system I'm usign the same setup with supervisord and uwsgi, not flask run
Sep 12 20:14:22 <SpeakerToMeat>	programmerq: I need to check if supervisord is set to respawn uwsgi or die... given it's inside a container I think it's set to die.. if I can set it to respawn uwsgi, I might be able to somehow signal uwsgi to restart
Sep 12 20:16:07 <helo>	I'd suggest some dev setup where you use flask run locally
Sep 12 20:16:16 <rolandas>	NOTevil: yes removed all volumes
Sep 12 20:16:45 <SpeakerToMeat>	helo: That would mean an extra Dockerfile appar form my extra docker-compose file... nad it would mean having different deploy and dev enviros which irk me slightly....
Sep 12 20:17:33 <helo>	normally I think you could have some environment variable that will select which command to use
Sep 12 20:18:00 <helo>	you still could run into some issue where you broke the startup command in prod and didn't notice, but that's what staging env is for :)
Sep 12 20:19:24 <SpeakerToMeat>	hmmmmmmmm I could wrap my supervisord entrypoint with a script, and check the environment for FLASK_ENV=development....
Sep 12 20:19:59 <helo>	yeah, exactly
Sep 12 20:32:38 <biam>	tabakhase: thanks for your help earlier. i was able to sort the CMD regex issue by using the shell form as opposed to the exec form
Sep 12 20:34:56 <tabakhase>	biam so was the $ actually the issue? - that was a complete moonshot after 2 seconds looking at the paste ;D - i was almost sure it would NOT be the fix after rereading your error message ;D (tho, "crypitc file not found"´s docker likes to spit in a ton of stupid cases...
Sep 12 20:37:20 <biam>	yeah, i'm not entirely sure. i think, when using the exec form of CMD, docker wasn't able to expand the regex.
Sep 12 20:37:31 <Keytap>	Is it safe to use the `#syntax=docker/dockerfile:experimental` directive in production?  I mean, it doesn't affect the output image.  The only reason I need to use it is for the RUN --mount option.
Sep 12 20:38:05 <tabakhase>	-> one case from memory that likes todo that "file not found scriptname" is when the file is totally there, - but the shebang in the file calls for bash on an alpine(ash) system or such... can drive people insane debugging :P
Sep 12 20:40:44 <helo>	^ so many times hah
Sep 13 07:15:49 *	Disconnected ()
**** ENDING LOGGING AT Fri Sep 13 07:15:49 2019

**** BEGIN LOGGING AT Fri Sep 13 07:16:13 2019

Sep 13 07:16:13 *	Now talking on #docker
Sep 13 07:16:13 *	Topic for #docker is: Docker: Open platform for distributed applications | http://docker.com | Certifications https://success.docker.com/certification | http://github.com/moby/moby | Current Status: http://status.docker.com/ | https://forums.docker.com/ | Registration with NickServ required: https://freenode.net/kb/answer/registration
Sep 13 07:16:13 *	Topic for #docker set by programmerq!~jeff@unaffiliated/programmerq (Fri Dec  7 20:42:52 2018)
Sep 15 22:38:27 *	Disconnected ()
**** ENDING LOGGING AT Sun Sep 15 22:38:27 2019

**** BEGIN LOGGING AT Sun Sep 15 22:38:53 2019

Sep 15 22:38:53 *	Now talking on #docker
Sep 15 22:38:53 *	Topic for #docker is: Docker: Open platform for distributed applications | http://docker.com | Certifications https://success.docker.com/certification | http://github.com/moby/moby | Current Status: http://status.docker.com/ | https://forums.docker.com/ | Registration with NickServ required: https://freenode.net/kb/answer/registration
Sep 15 22:38:53 *	Topic for #docker set by programmerq!~jeff@unaffiliated/programmerq (Fri Dec  7 20:42:52 2018)
Sep 16 00:19:18 *	Disconnected ()
**** ENDING LOGGING AT Mon Sep 16 00:19:18 2019

**** BEGIN LOGGING AT Mon Sep 16 00:19:45 2019

Sep 16 00:19:45 *	Now talking on #docker
Sep 16 00:19:45 *	Topic for #docker is: Docker: Open platform for distributed applications | http://docker.com | Certifications https://success.docker.com/certification | http://github.com/moby/moby | Current Status: http://status.docker.com/ | https://forums.docker.com/ | Registration with NickServ required: https://freenode.net/kb/answer/registration
Sep 16 00:19:45 *	Topic for #docker set by programmerq!~jeff@unaffiliated/programmerq (Fri Dec  7 20:42:52 2018)
Sep 16 09:05:08 *	Disconnected ()
**** ENDING LOGGING AT Mon Sep 16 09:05:08 2019

**** BEGIN LOGGING AT Mon Sep 16 09:05:35 2019

Sep 16 09:05:35 *	Now talking on #docker
Sep 16 09:05:35 *	Topic for #docker is: Docker: Open platform for distributed applications | http://docker.com | Certifications https://success.docker.com/certification | http://github.com/moby/moby | Current Status: http://status.docker.com/ | https://forums.docker.com/ | Registration with NickServ required: https://freenode.net/kb/answer/registration
Sep 16 09:05:35 *	Topic for #docker set by programmerq!~jeff@unaffiliated/programmerq (Fri Dec  7 20:42:52 2018)
Sep 16 09:38:47 <blip99>	Morning all!  When I mount a local directory into a container using docker-compose volumes './local_dir:/container/dir
Sep 16 09:39:10 <blip99>	I correctly see changes in a file propgated from local to container
Sep 16 09:39:22 <blip99>	however when i restart container, it resets the changes in my local file!
Sep 16 09:39:33 <blip99>	how can that possible happen?  It's a 1-way mount
Sep 16 09:54:03 <RV06>	blip99, does your image have an entrypoint script that could reset the changes ?
Sep 16 09:55:29 <blip99>	RV06, I didn't write the project but trying to understand it.  No the entrypoint doesn't.  The Dockerfile has a bunch of copies though - could that be it?
Sep 16 09:57:15 <blip99>	ok the COPY commands go host->docker as far as I can tell (I don't think you can do docker->host there)
Sep 16 09:57:16 <RV06>	The Dockerfiles actions are executed at image creation.
Sep 16 09:57:42 <blip99>	let me check, I think local gets overwriten only when I rebuild
Sep 16 09:57:47 <RV06>	they go host=>image, then you create a container from the image
Sep 16 09:57:47 <blip99>	2 mins
Sep 16 09:57:58 <blip99>	ah right
Sep 16 09:58:17 <RV06>	it's quite important to make the distinction between image and container.
Sep 16 10:01:45 <blip99>	ok just confirmed, simply restarting containers over-writes changes in host fs
Sep 16 10:02:10 <blip99>	RV06, ah I didn't think that affects the writing to host issue
Sep 16 10:03:54 <blip99>	ok so while the container is running - changes to host FS propagate through to container FS.   as expected
Sep 16 10:04:19 <blip99>	restarting the container resets the host fs changes.   Must be something in the scripts somewhere!
Sep 16 10:04:25 <blip99>	I just don't know what to look for
Sep 16 10:04:37 <RV06>	Are you really confident on the container's entrypoint + command behaviour ?
Sep 16 10:04:56 <blip99>	I used to understand Docker, can't believe it's all out of the window now :D
Sep 16 10:05:06 <RV06>	"docker inspect" will give you the entrypoint and command
Sep 16 10:06:27 <RV06>	you could test by creating a similar container with overridden entrypoint and command (like bash + sleep infinity)
Sep 16 10:06:29 <blip99>	ah 1 sec, the entrypint has a exec "$@".   Let me see the command in docker-compose
Sep 16 10:09:42 <blip99>	btw there's 5 containers, but they all use same Dockerfile.  only difference is the command in docker-compose
Sep 16 10:10:12 <blip99>	just checked inspect, 4 containers simply start a program (airflow)
Sep 16 10:11:01 <blip99>	but the 5th runs a script which has:  'rsync -avz  --delete /some_dir/ /dir1/dir2'
Sep 16 10:11:22 <blip99>	that doesnt look like host fs though, it's all in the container fs right?
Sep 16 10:15:45 <blip99>	this is insane
Sep 16 10:15:56 <blip99>	im gonna comment out everything and slowly add stuff in
Sep 16 10:16:09 <blip99>	to isolate which container over-writes, and where it over-writes
Sep 16 10:20:26 <blip99>	RV06, do i need to rebuild an image to propagate changes to entrypoint.sh?
Sep 16 10:21:47 <RV06>	blip99, if your entrypoint is 'exec "$@"' there's no need to override it.
Sep 16 10:22:09 <RV06>	you can just change your command.
Sep 16 10:22:28 <RV06>	All that can be done in your docker-compose files.
Sep 16 10:23:04 <RV06>	...the rsync looks like a good lead though.
Sep 16 10:31:21 <lxsameer>	hey folks, is it possible to run a container entirely in memory ( including the volumnes )
Sep 16 10:34:18 <blip99>	RV06, I'm getting very close, just a silly thing this doesn't work:  command: ["sh", "sleep infinity"]
Sep 16 10:34:28 <blip99>	sh: 0: Can't open sleep infinity
Sep 16 10:34:40 <blip99>	sorry it's a really basic question
Sep 16 10:38:59 <blip99>	oh that was dumb, nvm command: ["sleep", "infinity"]
Sep 16 10:42:28 <RV06>	lxsameer, https://docs.docker.com/storage/tmpfs/
Sep 16 10:43:08 <lxsameer>	RV06: hmm that's only for the storage, right ?
Sep 16 10:43:23 <blip99>	RV06, ok indeed it's the rsync.  Thanks for the help figuring out.  Now I need to know why on earth the author did this...
Sep 16 10:44:07 <RV06>	great blip99 !
Sep 16 10:44:50 <RV06>	lxsameer, that's for volumes. You want the image to be in memory as well ?
Sep 16 10:46:31 <blip99>	RV06, so when the entrypoint runs and receives the 'command' from docker-compose - all of this is running in the container no?  Cos the rsync paths aren't host fs... i dont get how it's writing to it
Sep 16 10:47:09 <blip99>	both paths start with /, which isn't the path of the over-written file on host..
Sep 16 10:47:12 <blip99>	so strange
Sep 16 10:47:44 <lxsameer>	RV06: yes, everything in memory
Sep 16 10:50:18 <RV06>	blip99, yes, it runs in the container. But rsync writes in the mount path at a moment. Maybe some symlinks ?
Sep 16 10:51:13 <RV06>	lxsameer, I don't catch the reason to do so, but you could create a tmpfs on your host for /var/lib/docker.
Sep 16 10:51:58 <RV06>	lxsameer, the path for images is global to your docker instance, so AFAIK there's no way to have it in memory for one container and on disk for another.
Sep 16 10:54:07 <lxsameer>	RV06: hmm no problem. I just can use it for all the containers
Sep 16 10:54:13 <lxsameer>	RV06: thanks
Sep 16 10:56:28 <blip99>	RV06, I acutally didn't realize the volume mount goes both ways - thought it only did host->container not vice versa :D
Sep 16 10:57:05 <blip99>	at the same time, we actually want to be able to write to host when we run in production - cos some parts of the software need to write to disk
Sep 16 10:57:41 <blip99>	So I'll probably just have a check in the script for an env var - to have different behavior when it runs in prod vs when we develop the project :)
Sep 16 10:57:52 <RV06>	Right. That's a bind mount.
Sep 16 10:58:35 <RV06>	blip99, you could check for the volume contents: if empty, init it with rsync. Otherwise keep it as it is.
Sep 16 11:00:12 <RV06>	(but beware that some empty volumes may have some files like "lost+found")
Sep 16 11:09:11 <blip99>	RV06, well it will only be empty on first run of fresh container, the rsync should propagate changes when you restart container (even if not empty)
Sep 16 12:01:20 <gdrc>	maybe off-topic: nodejs's function to check if a file exists return false on a file that is in a dir that I mounted with --volume. I've checked the linux permission and looks fine. What else should I check? Thanks.
Sep 16 12:42:56 <nmee>	Hi! I have a problem with `docker run` downloading a new image from the registry even if it should exist locally -- from `docker images` I can see that a particular image is present locally, but `docker run` still downloads the latest image (the image _has_ changed). I thought `docker run` wouldn't check the registry for updates if the image was already present?
Sep 16 12:49:16 <Celmor[m]>	docker run never checks for updates, it simply checks if there's a local image with the given tag, except if you specify an image id
Sep 16 12:55:13 <nmee>	Right, that is what I was expecting -- it does say however that the image was not found locally (and thus proceeds with downloading it). The image should absolutely be present though -- I can see it in `docker images` with the correct repository, image name and tag
Sep 16 13:19:09 <mgolisch>	sure you ran it with that tag?
Sep 16 13:19:16 <mgolisch>	if you dont specify a tag it will use latest
Sep 16 13:20:41 <pix9>	hey folks need to know about doker overlay, found some filess with full permission under docker overlay path over centos7
Sep 16 13:21:52 <pix9>	currently referring to https://docs.docker.com/storage/storagedriver/overlayfs-driver/
Sep 16 13:26:10 <nmee>	mgolisch: the tag in question _is_ `latest` -- but we're explicitly specifying the tag though, but might still that be the issue?
Sep 16 13:26:31 <nmee>	I'll double check that we are specifying "latest" also when running docker run (and not only when pushing the tag)
Sep 16 15:45:11 *	Disconnected ()
**** ENDING LOGGING AT Mon Sep 16 15:45:11 2019

**** BEGIN LOGGING AT Mon Sep 16 15:45:39 2019

Sep 16 15:45:39 *	Now talking on #docker
Sep 16 15:45:39 *	Topic for #docker is: Docker: Open platform for distributed applications | http://docker.com | Certifications https://success.docker.com/certification | http://github.com/moby/moby | Current Status: http://status.docker.com/ | https://forums.docker.com/ | Registration with NickServ required: https://freenode.net/kb/answer/registration
Sep 16 15:45:39 *	Topic for #docker set by programmerq!~jeff@unaffiliated/programmerq (Fri Dec  7 20:42:52 2018)
Sep 16 16:11:20 <tabakhase>	dka depends... - those ports are not exposed to the public, but to "every docker container in the network" - so a random other docker could find that, and own the system from it +  it seems "most of the time" gitlab checks the tls port, so it would be "faster" not having to wait 30sec. for timeout --- ((note that depending on hardware key-generation can take a bit tho! a 1-core-vps-runner-farm
Sep 16 16:11:20 <tabakhase>	i have takes almost 25seconds to start with tls-generation... - also "gitlab checks a random port" so this may flip any day, so if thats rly a concern one is better off mirroring docker:dind completly, and build from it with "EXPOSE {}" (i think?) && "EXPOSE actualusedPort"...
Sep 16 16:22:39 <C0nundrum>	Hello, if i have docker on nexus is there a way for me to push and pull images without using the full nexus url for the image ?
Sep 16 16:23:07 <C0nundrum>	If i have a docker repository on nexus*
Sep 16 16:24:14 <programmerq>	C0nundrum▸ docker uses the url as part of the image name to namespace everything by design.
Sep 16 16:25:35 <tabakhase>	(and the default is not even changeable if i remember right, so you need to use "full names all the time" ether way)
Sep 16 16:26:42 <C0nundrum>	Ok wasn't sure if i was missing something because the nexus page says for an image go/myimage in the repository ,i can fetch it with docker pull go/myimage
Sep 16 16:27:44 <C0nundrum>	but that isn't the case, i have to do nexus.mysite.com:5000/go/myimage
Sep 16 16:27:44 <tabakhase>	not sure what youre looking at, but firt google result cleary has the domain in the example too https://help.sonatype.com/repomanager3/formats/docker-registry/pushing-images
Sep 16 16:28:23 <C0nundrum>	on the specification for the image on the actual nexus gui
Sep 16 16:28:43 <C0nundrum>	under usage but i guess that's just outdated
Sep 16 16:31:35 <tabakhase>	hm, no clue what nexus itself is ;D - but maybe that has its own cli tool that pads that or so? ((there are some other "docker forks/interfaces" kinda deals that do such things...))
Sep 16 16:31:56 <tabakhase>	(aka "docker build" becomes "XY build" and such)
Sep 16 16:33:57 <Swahili>	Q: I have two different containers, created from two different images, that I'd like to share a particular volume (Service1 and Service2); Service1 generates some files in `/home/node/app/public` and Service2 should serve these files, but has the nginx root set to `/var/www/html`. I started by creating volume `public_html` and declared it under Service1 like so `- public_hmtl:/var/www/html/public`. I think that in Service2 I hav
Sep 16 16:33:57 <Swahili>	e to `- public_html:/var/www/html` and because the dest directory is empty the volume data in public_html should persist?
Sep 16 16:34:05 <Swahili>	Is this correct?
Sep 16 16:34:35 <programmerq>	correct-- when you have a volume, the data in the volume will persist in the volume.
Sep 16 16:37:21 <Swahili>	Thanks programmerq :) I'll try
Sep 16 16:38:27 <C0nundrum>	gotcha thanks for info
Sep 16 16:38:35 <C0nundrum>	Thanks for the info*
Sep 16 16:38:59 <Swahili>	Q: When we re-use the same `image: imageName` between services, does Docker use the same container? The reason why I ask, is to make sure I'm not setting concurrent app source files under the same pathname such as `/var/www/html` or so.
Sep 16 16:39:37 <programmerq>	Swahili▸ no, it does not use the same container. it uses the same image.
Sep 16 16:40:24 <Swahili>	programmerq: thanks for confirming! There's no such thing as two difference services using the same container?
Sep 16 16:41:04 <programmerq>	correct
Sep 16 16:41:37 <Swahili>	Thank you programmerq!
Sep 16 16:43:09 <pid1>	I have a one-off container that runs a Python program daily that compiles some information and spits it out to a file. Previously I had this and an nginx container on a single host just sharing a volume so I could provide web access to the file content (and old versions). I would like to make this HA and run on a couple of swarm workers. Is there a recommended way of configuring setups like this? I didn't want to go down the route of sharing a ceph
Sep 16 16:43:09 <pid1>	volume if that was overkill.
Sep 16 16:44:09 <programmerq>	pid1▸ sharing data between hosts _does_ require some sort of file sharing system in place-- whether ceph or something else.
Sep 16 16:44:36 <programmerq>	nfs might work too
Sep 16 16:44:53 <programmerq>	you can even feed info to docker to say "hey mount this nfs at this location in this container"
Sep 16 16:45:51 <pid1>	Cool, that's what I figured. I wanted to make sure there wasn't a better way to solve this. Thanks!
Sep 16 16:47:03 <angular_mike>	 having issue with installing gevent in docker: https://termbin.com/j4gb
Sep 16 16:51:03 <mgolisch>	angular_mike: which python version do you use?
Sep 16 16:52:12 <mgolisch>	https://github.com/gevent/gevent/issues/1297
Sep 16 16:52:30 <mgolisch>	looks like you need atleast 1.3 for python 3.7
Sep 16 16:57:33 <angular_mike>	hm, so i should force-install a newer gevent version?
Sep 17 10:23:00 *	Disconnected ()
**** ENDING LOGGING AT Tue Sep 17 10:23:00 2019

**** BEGIN LOGGING AT Tue Sep 17 10:23:27 2019

Sep 17 10:23:27 *	Now talking on #docker
Sep 17 10:23:27 *	Topic for #docker is: Docker: Open platform for distributed applications | http://docker.com | Certifications https://success.docker.com/certification | http://github.com/moby/moby | Current Status: http://status.docker.com/ | https://forums.docker.com/ | Registration with NickServ required: https://freenode.net/kb/answer/registration
Sep 17 10:23:27 *	Topic for #docker set by programmerq!~jeff@unaffiliated/programmerq (Fri Dec  7 20:42:52 2018)
Sep 17 10:26:00 <tnewman>	regarding traefik, whats the difference between yml vs toml?  when do i use one over the other?
Sep 17 10:26:35 <cim209>	tnewman: preference i guess. i prefer keeping the configs in the yml
Sep 17 10:33:03 <tnewman>	uhuh
Sep 17 10:33:43 <mgolisch>	why would that be awesome?
Sep 17 10:48:32 <Swahili>	Q: I'd like to test Traefik that was suggested to me yesterday and following the docs, the most basics the localhost:8080 does not work. The docker-compose.yml is the first step of the basics tutorial here 1 — Launch Traefik — Tell It to Listen to Docker¶
Sep 17 10:48:55 <Swahili>	Does anyone mind have a look to see if it's just my machine?
Sep 17 10:53:17 <tnewman>	hey Swahili perhaps you've run into my problem
Sep 17 10:53:53 <tnewman>	try the guide specific to v2 here https://docs.traefik.io/v2.0/getting-started/quick-start/#launch-traefik-with-the-docker-provider
Sep 17 10:54:06 <tnewman>	use that docker-compose.yml
Sep 17 10:55:36 <Swahili>	tnewman: thanks for looking! I'll check ; )
Sep 17 10:56:42 <tnewman>	yeah they must have just updating things very recently
Sep 17 10:56:44 <Swahili>	tnewman: yeh it worked
Sep 17 10:56:47 <tnewman>	awesome!
Sep 17 10:56:57 <cim209>	v2 came out yesterday
Sep 17 10:57:00 <Swahili>	tnewman: why is this happening? is it just macos related?
Sep 17 10:59:23 <tnewman>	i think its that v2 came out yesterday
Sep 17 10:59:45 <tnewman>	not an OS X thing
Sep 17 11:00:13 <Swahili>	just stepping in, and wondering what do you people do in production, 8080 is not public is it? this dashboard
Sep 17 11:00:33 <cim209>	Swahili: you have to use the traefik.port labels for the dashboard
Sep 17 11:00:48 <cim209>	because 8080 does not work with https
Sep 17 11:00:54 <cim209>	or any other ports
Sep 17 11:01:43 <cim209>	unless you want to jump hoops to use a different HTTPS port other than 443
Sep 17 11:01:52 <Swahili>	Ok! I'll be learning this for the next few hours. I was advised here and this looks nice. Actually I found this web server and reverse proxy called Caddy that looked super easy too
Sep 17 11:02:27 <Swahili>	cim209: that's alright! ; )
Sep 17 11:02:56 <Swahili>	This will work with amazon ecs it seems
Sep 17 11:58:43 <akik>	how would i use docker cp on a swarm to copy files from containers without knowing on which host the containers run on?
Sep 17 12:06:20 <tuskkk____>	hello!
Sep 17 12:06:20 <tuskkk____>	am trying to run a jar built using clojure in the openjdk 8 alpine image using `CMD ["java", "-jar", "app-standalone.jar"]` but all I get is `Clojure 1.8.0 user=>` and then it terminates. Any ideas?
Sep 17 12:41:19 <mgolisch>	tuskkk____: what does the app do?
Sep 17 12:51:43 <mgolisch>	tuskkk____: looks like a repl, it probably requires a terminal
Sep 17 13:18:30 <tuskkk____>	mgolisch: it exposes and endpoint
Sep 17 13:18:34 <tuskkk____>	an*
Sep 17 13:47:09 <mgolisch>	looks like it starts a clojure repl
Sep 17 13:47:13 <mgolisch>	is that intended?
Sep 17 13:47:24 <mgolisch>	does the same jar file work if you run it on your box?
Sep 17 13:53:05 <gsearle>	I want to use swap space for applications running in my docker containers, but Kubernetes said I can't. Has anyone else solve this problem?
Sep 17 13:54:27 <Ckat>	I'm not quite sure where to get permissions fixed for volumes created in a docker-compose.yml
Sep 17 13:54:41 <Ckat>	dockerfile? right under it? somewhere else?
Sep 17 13:56:59 <Ckat>	its a mariadb based container and the volumes look like ./datadir:/var/libmysql and ./tmpdir:/tmp but after creation the container gets permission denied on /tmp. which is fixed when doing chmod 757 on the ./tmpdir from host
Sep 17 14:11:08 <mgolisch>	whats that mount good for?
Sep 17 14:12:11 <mgolisch>	why do you need access to or persist /tmp ?
Sep 17 14:14:35 <Ckat>	thats how its setup, this isnt mine its form a coworker
Sep 17 14:17:44 <mgolisch>	but yeah youd change the permissions in your entrypoint
Sep 17 14:17:49 <mgolisch>	if you want to automate that
Sep 17 14:22:23 <cyberjunkie>	Why would one use Traefik? Won't it be simpler to route/forward ports from a VPS to a remote server , through a VPN?
Sep 17 14:22:47 <cyberjunkie>	I have a VPS, and I want to host some stuff remotely (at home) on my Raspberry Pi.
Sep 17 14:48:25 <mgolisch>	its simple?
Sep 17 14:48:35 <mgolisch>	you want to use multiple things on port 443/80
Sep 17 14:48:45 <tuskkk____>	mgolisch: sorry I was away, I got it running in the end, thanks!
Sep 17 14:48:51 <mgolisch>	tuskkk____: cool
Sep 17 15:05:12 <Elodin>	Hello, i have this flask application i have been running with sqlite. So far the database is in the same dir of the application code. Should i make a volume for it?
Sep 17 15:20:53 <Cheaterman>	I'm sad :-( https://github.com/docker/for-linux/issues/488#issuecomment-532206947
Sep 17 15:20:56 <Cheaterman>	I wasted like 3h on this
Sep 17 15:21:24 <Cheaterman>	Mostly wondering why it works on one machine and not the other - until I noticed one is 17.09 and the other 18.09
Sep 17 15:21:55 <Cheaterman>	In any case it doesn't feel "right" that such a backward-incompatible change to the networking system was made
Sep 17 15:22:15 <Cheaterman>	and it's puzzling to me that no one noticed it, since docker-compose creates a user-defined network by default, which should trigger the bug
Sep 17 15:22:19 <programmerq>	I was under the impression that the docker dns forwarding never worked with /etc/hosts -- unless you had a resolver on your host that took that into account.
Sep 17 15:22:32 <Cheaterman>	programmerq: the real issue is resolv.conf here
Sep 17 15:22:39 <Cheaterman>	the embedded DNS server is supposed to take it into account
Sep 17 15:22:42 <Cheaterman>	and, well, it did.
Sep 17 15:22:50 <programmerq>	resolv.conf on the host on in the container?
Sep 17 15:22:56 <programmerq>	in the container, it should be 127.0.0.11
Sep 17 15:23:08 <Cheaterman>	Yes → user defined network, so embedded DNS ,so 127.0.0.11 in container
Sep 17 15:23:12 <Cheaterman>	however can't resolve names in there!
Sep 17 15:23:28 <Cheaterman>	until I add "network_mode: 'bridge'" to docker-compose
Sep 17 15:23:29 <programmerq>	and the names you're trying to resolve are resolvable on the host?
Sep 17 15:23:35 <Cheaterman>	google.com? Yes it is
Sep 17 15:23:36 <programmerq>	using dig?
Sep 17 15:23:39 <Cheaterman>	using ping
Sep 17 15:23:45 <programmerq>	oh, an external name isn't resolvable?
Sep 17 15:23:48 <Cheaterman>	yes :-(
Sep 17 15:23:50 <Cheaterman>	makes me very sad
Sep 17 15:23:50 <programmerq>	and, ping is *not* a dns resolution tool
Sep 17 15:24:07 <programmerq>	that's most likely a fixable issue on your system and not a design change in docker that's irreconcileable.
Sep 17 15:24:09 <Cheaterman>	I know, but at least it shows that things work. I could use "dig" to double check, but instead I removed my actual server from resolv.conf
Sep 17 15:24:13 <programmerq>	what does your host /etc/resolv.conf look like?
Sep 17 15:24:18 <programmerq>	are you using systemd-resolved ?
Sep 17 15:24:30 <Cheaterman>	Nope programmerq, and made sure /run/systemd/resolve/** is removed
Sep 17 15:24:48 <programmerq>	what distro are you using?
Sep 17 15:24:53 <Cheaterman>	Debian on both machines
Sep 17 15:24:56 <Cheaterman>	same resolv.conf on both macihnes
Sep 17 15:25:00 <Cheaterman>	one has 17.09 one has 18.09
Sep 17 15:25:02 <programmerq>	and /etc/resolv.conf on the host has what?
Sep 17 15:25:27 <programmerq>	which debian? buster?
Sep 17 15:25:36 <Cheaterman>	"domain openstack\nsearch openstack\nnameserver 127.0.0.1\nnameserver 213.186.33.99"
Sep 17 15:25:57 <programmerq>	what nameserver is running on your host?
Sep 17 15:26:04 <Cheaterman>	9.2 on the working machine, 9.6 on the other
Sep 17 15:26:06 <programmerq>	systemd-resolved ? dnsmasq ?
Sep 17 15:26:14 <Cheaterman>	dnsmasq, but that's for resolving VPN hosts
Sep 17 15:26:20 <Cheaterman>	irrelevant here - and again, BOTH MACHINES have this setup
Sep 17 15:26:35 <Cheaterman>	the main difference between the two machines really is the docker version
Sep 17 15:26:48 <Cheaterman>	also, I've seen SEVERAL mention that 18.09 breaks networking, so I think it's NOT an isolated inciddent
Sep 17 15:26:49 <programmerq>	it's absolutely relevant
Sep 17 15:26:59 <programmerq>	okay
Sep 17 15:27:02 <Cheaterman>	how so? it's not used to resolve google.com
Sep 17 15:27:05 <Cheaterman>	(and can't be)
Sep 17 15:27:10 <programmerq>	do you want me to help, or do you want to argue?
Sep 17 15:27:52 <Cheaterman>	I'd like you to help, if you want
Sep 17 15:28:04 <programmerq>	I'm happy to help, but please don't argue against my information gathering questions.
Sep 17 15:28:26 <Cheaterman>	Ask away then :-)
Sep 17 15:28:41 <Cheaterman>	Anything else you need to know?
Sep 17 15:29:03 <programmerq>	can you resolve vpn-specific addresses from within the container (use dig)
Sep 17 15:29:34 <Cheaterman>	pretty hard to use dig, the image doesn' thave it, and if I don't have the network I can't install it
Sep 17 15:29:37 <Cheaterman>	:-/
Sep 17 15:29:56 <programmerq>	docker run --rm -it --net container:<existingcontainer> nicolaka/netshoot drill <record>
Sep 17 15:30:07 <programmerq>	(drill is like dig)
Sep 17 15:30:21 <Cheaterman>	Ok
Sep 17 15:31:39 <Cheaterman>	programmerq: Good one - got resolution for the VPN, not for external stuff
Sep 17 15:31:52 <Cheaterman>	resolv.conf on host should be reordered I assume? :-/
Sep 17 15:32:23 <Cheaterman>	Again - works on the other machine. With the SAME resolv.conf in the SAME order
Sep 17 15:32:27 <programmerq>	that may help, it may not. It may swap what's broken.
Sep 17 15:32:42 <Cheaterman>	programmerq: keep in mind, the 17.09 machine works perfectly with the same config
Sep 17 15:32:55 <programmerq>	stop saying that please. repeating it won't help moving forward.
Sep 17 15:33:02 <Cheaterman>	Ok, what do I do now?
Sep 17 15:33:48 <learningc>	Can I run a Windows game using docker?
Sep 17 15:34:04 <programmerq>	with that said, I've always operated under the assumption that /etc/resolv.conf is supposed to have nameservers that are basically redundant to eachother. having one that can do some records and one that can do another record goes against that pattern-- I think you've opted into something that isn't guaranteed across different interpretations of things. docker just happens to be the first thing you ran into
Sep 17 15:34:06 <programmerq>	that doesn't react properly to this unconventional setup. I'd argue
Sep 17 15:34:27 <gsearle>	learningc: I think you want to use Wine.
Sep 17 15:34:42 <Ckat>	any reason I get unsupported Compose file version: 2.2 when my docker is 19.03.2 and my compose is 1.24.1?
Sep 17 15:34:46 <programmerq>	that instead of having two separate dns servers that you hope things can resolve against, you should have a dns server that does the correct thing-- set up your dnsmasq locally to resolve all the records intelligently, and point /etc/resolv.conf to that.
Sep 17 15:34:47 <Ckat>	isnt it backwards compatible?
Sep 17 15:34:56 <mgolisch>	Ckat: swarm?
Sep 17 15:35:00 <Ckat>	yea
Sep 17 15:35:05 <learningc>	gsearle, but Wine is not a container isn't it?
Sep 17 15:35:11 <Cheaterman>	programmerq: So you're gonna entirely dismiss the fact that it worked on 17.09? I was repeating it for a reason.
Sep 17 15:35:11 <gsearle>	Wine has bottle that are containers that are windows enviroments.
Sep 17 15:35:16 <mgolisch>	swarm mode requires version 3.x compose files
Sep 17 15:35:27 <Cheaterman>	You're also gonna dismiss the fact that host resolves everything fine? Both VPN and external?
Sep 17 15:35:28 <Ckat>	ah
Sep 17 15:35:54 <Ckat>	I recall being able to throw a stack together with these before.. is there around using it for a swarm? can I pass it the images instead or something?
Sep 17 15:36:02 <programmerq>	so while it's entirely possible that the docker version is the difference here (you also mentioned that you're on 9.2 and 9.6, and that's another difference), I'd recommend moving to a more robust setup and not rely on a particular combination of package and distro versions to act a certain way with a weird /etc/resolv.conf setup with diverging, non-redundant resolvers.
Sep 17 15:36:04 <Cheaterman>	programmerq: It's also probably relevant that "network_mode: 'bridge'" solves the issue. Why does that work?
Sep 17 15:36:33 <Cheaterman>	inspecting the networks reveal absolutely no difference between "network_mode: 'bridge'" and default
Sep 17 15:36:42 <Cheaterman>	That's also something that puzzled me a lot
Sep 17 15:36:55 <programmerq>	Cheaterman▸ that connects you to the docker0 default network, which is the legacy docker network. instead of getting 127.0.0.11, you'll get a copy of your host's /etc/resolv.conf, but with s/127.0.0.1/8.8.8.8/
Sep 17 15:37:06 <programmerq>	or maybe since you have another one in there, it'll use only that one
Sep 17 15:37:27 <Cheaterman>	programmerq: That is incorrect
Sep 17 15:37:28 <programmerq>	so you're cutting out the service discovery feature and forcing it to use the public dns server, basically.
Sep 17 15:37:32 <Cheaterman>	programmerq: The resolv.conf still has 127.0.0.11
Sep 17 15:37:37 <Cheaterman>	even with network_mode: 'bridge'
Sep 17 15:37:38 <programmerq>	interesting
Sep 17 15:37:41 <programmerq>	not sure then.
Sep 17 15:37:44 <Cheaterman>	that's why I'm having issues understanding here.
Sep 17 15:37:47 <Cheaterman>	Okay :-) thanks anyway!
Sep 17 15:38:11 <Cheaterman>	programmerq: then we are both reaching the conclusion that something broke between 17.09 and 18.09, as the issue concluded?
Sep 17 15:38:17 <programmerq>	learningc▸ windows containers can't run windows gui programs. you can run windows gui via wine+x11, run that in a container with a remote x11 display, but that's probably not what you're asking about.
Sep 17 15:38:33 <programmerq>	Ckat▸ the version needs to be a string.
Sep 17 15:38:59 <programmerq>	Ckat▸ oh, nevermind someone else already got you sorted-- yeah, docker stack deploy needs a version 3.x syntax
Sep 17 15:39:53 <programmerq>	Cheaterman▸ you haven't provided enough information to convice me that's it since you're running different versions of the debian os. it could be docker, it could be the way docker calls out to the resolver library on both those versions. with some more testing and eliminating more variables, it's possible that it could be a behavior change in docker, yes
Sep 17 15:40:58 <Cheaterman>	programmerq: that's a fair point indeed - TBH I wasted wayyy too much time on this already
Sep 17 15:41:02 <programmerq>	but I would argue it's irrelevant because it's bad practice to rely on a specific behavior with a novel/non-standard setup. /etc/resolv.conf should point to dns servers that are equally capable. if one returns "no such record", that's an actual response that it can pass back.
Sep 17 15:41:07 <Cheaterman>	and I gotta do the actual things I set up my docker services for ^^
Sep 17 15:41:07 <mgolisch>	then again you should probably not have nameservers in your resolv.conf that only resolve some domains, that might lead to weird issues
Sep 17 15:41:34 <programmerq>	and you're relying oh hoping every possible thing doing a resolution will fall back to the other nameserver when it gets a particular dns response from one server.
Sep 17 15:42:05 <Cheaterman>	programmerq: I understand that, but I've been using this setup for decades now
Sep 17 15:42:12 <Cheaterman>	and it works for hosts
Sep 17 15:42:29 <Cheaterman>	and it *used* to work inside Docker
Sep 17 15:42:54 <programmerq>	arguably, this is a bug that was fixed somewhere. hammering both dns servers for a true 'record not found' sounds like bad form
Sep 17 15:43:01 <Cheaterman>	mgolisch: :-/ really this works on all hosts, and used to work inside Docker, only today did I first run into an issue
Sep 17 15:43:15 <Cheaterman>	programmerq: I would agree if host resolution didn't do that
Sep 17 15:43:43 <Ckat>	whats the compose 3.x notation for the old cpu_count: ?
Sep 17 15:43:45 <programmerq>	different things can have bad behaviors and still have it be how it behaves.
Sep 17 15:43:54 <Cheaterman>	There is IIRC some way to stop if notfound, like [NOTFOUND=return] in nsswitch.conf, programmerq
Sep 17 15:44:14 <Cheaterman>	Yes, that's fair, but still, some things work the way they do by fiat
Sep 17 15:44:27 <Cheaterman>	and changing that to better suit what they "should" do isn't necessarily practical
Sep 17 15:44:33 <Cheaterman>	(practicality beats purity anyday in my book)
Sep 17 15:45:03 <programmerq>	Ckat▸ https://docs.docker.com/compose/compose-file/ - this is your friend. swarm-specific stuff is generally found under the deploy: key.
Sep 17 15:46:34 <Ckat>	programmerq: thats where I was, and didnt see cpu_count, it doenst like being under limits or deploy
Sep 17 15:47:16 <programmerq>	cpu_count is the regular containers api setting, not the swarm mode setting
Sep 17 15:47:24 <programmerq>	they aren't all 1:1, which is why there's the deploy key
Sep 17 15:47:29 <programmerq>	so go look under deploy for what's there
Sep 17 15:47:48 <programmerq>	'docker service create --help' there's no cpu_count here either, but there are cpu limit settings
Sep 17 15:54:44 <Swahili>	Q: If you don't mind me asking about Traefik, following the oficial docs I'm not finding the reference for where label properties come from for example traefik.http.routers.my-container.rule=Host(`xxxx.docker.localhost`)
Sep 17 15:54:54 <Swahili>	I'm basically following examples I can find.
Sep 17 15:55:43 <Swahili>	so you go through the getting started and shows the whoami example and then BAAM https://docs.traefik.io/v2.0/providers/docker
Sep 17 16:03:09 <mgolisch>	?
Sep 17 16:07:41 <learningc>	programmerq, so docker isn't really a container for every applications which I thought could replace a VM?
Sep 17 16:08:14 <programmerq>	learningc▸ not windows gui applications and not wayland gui applications currently
Sep 17 16:08:36 <jtreminio>	new traefik v2 breaks old configs :(
Sep 17 16:08:47 <programmerq>	although now that I think about it-- you might be able to pass all the hardware into the container and run wayland in the container that way
Sep 17 16:08:51 <learningc>	programmerq, is there any plan to support gui and games?
Sep 17 16:08:52 <programmerq>	not sure though, haven't played with it.
Sep 17 16:09:14 <jtreminio>	learningc, there's nvidia-docker for AI work
Sep 17 16:09:15 <programmerq>	learningc▸ well, keep in mind that windows containers in application isolation mode only works on windows server 2016
Sep 17 16:09:21 <programmerq>	on windows 10, windows containers use hyper-v
Sep 17 16:09:43 <programmerq>	so even if it did work with gui, the gpu wouldn't be in the hyper-v isolation
Sep 17 16:09:51 <learningc>	I see
Sep 17 16:09:58 <jtreminio>	nvidia docker is only linux, yeah
Sep 17 16:09:58 <programmerq>	and at that point, you might as well run the game in a full blown hyper-v vm
Sep 17 16:10:23 <learningc>	Is docker a Linux container?
Sep 17 16:10:43 <dude-x>	programmerq can windows containers run IE, Chrome, Firefox, etc?
Sep 17 16:10:49 <programmerq>	...
Sep 17 16:10:51 <dude-x>	in isolation?
Sep 17 16:10:59 <programmerq>	read above re: windows gui containers...
Sep 17 16:11:23 <dude-x>	programmerq ah i see. dang.
Sep 17 16:11:28 <tabakhase>	the simple answer to "windows games in docker" is No.
Sep 17 16:11:40 <dude-x>	games? i'm thinking browser automation
Sep 17 16:11:48 <vegardx>	So use a headless?
Sep 17 16:11:50 <tabakhase>	and docker is specifically "not a vm"
Sep 17 16:12:06 <vegardx>	selenium has all the things you need to run it in containers, headless and whatnot
Sep 17 16:12:09 <learningc>	tabakhase, dang. that's the answer I wanted to hear, but not the correct answer I wanted to hear.
Sep 17 16:12:09 <dude-x>	windows has unique characteristics
Sep 17 16:12:49 <programmerq>	learningc▸ what games do you want to containerize? what problem are you trying to solve?
Sep 17 16:12:51 <dude-x>	i'm fine with linux/mac automation for browsers, but i guess in a few years windows containers will be a thing,
Sep 17 16:12:53 <learningc>	vegardx, selenium? you mean including windows games??
Sep 17 16:13:08 <dude-x>	two different threads
Sep 17 16:13:23 <tabakhase>	dude-x idk about you, but that dude was asking for games from what i see in my scrollback ;D -- for browser stuff, headless chrome is just fine for 99% so i wouldnt worry to much... not like you can rly automate IE or so anyways
Sep 17 16:13:30 <programmerq>	dude-x▸ windows containers *are* a thing
Sep 17 16:13:37 <vegardx>	learningc: I'm not sure where games came in. Selenium is a testing framework that can work with headless browsers.
Sep 17 16:14:00 <programmerq>	ah Ckat was the one who asked the games question
Sep 17 16:14:02 <tabakhase>	been having some fun with puppeteer myself recently...
Sep 17 16:14:05 <dude-x>	tabakhase selenium works with IE7-11 (newest version only works with 11)
Sep 17 16:14:05 <programmerq>	I've got my wires crossed, lol
Sep 17 16:14:52 <dude-x>	headless works fine in Linux, but headless Chrome and headless firefox do not behave the same as regular Chrome and regular firefox
Sep 17 16:14:53 <learningc>	programmerq, basically and ideally I want a lean Windows machines where I can run everything in container and uninstall applications which would leave Windows settings and registry pristine
Sep 17 16:15:14 <vegardx>	dude-x: That I'd like to see proof of
Sep 17 16:15:47 <vegardx>	We run quite literally thousands of integration tests in headless per day. I can't really see how we wouldn't have stumbled upon that.
Sep 17 16:16:17 <dude-x>	vegardx you can do basic automation fine with headless, but if you do things like download files or some certain actions that are atypical, you may run into problems. these issues are documented on their respective sites (i'm not including bugs)
Sep 17 16:16:41 <dude-x>	vegardx what do you define as headless, Chrome with xvfb or chrome with --headless option?
Sep 17 16:16:42 <learningc>	What is headless chrome and firefox?
Sep 17 16:16:44 <tabakhase>	learningc nothing of that sort exist - "docker" is a linux thing - and the "windows docker" is about windows-server-2019 ussage  --- now this is not rly "true answer" but kinda the answer to your Q.
Sep 17 16:16:58 <dude-x>	learningc headless means without monitor, without rendering to a real graphics thingie
Sep 17 16:17:12 <vegardx>	Just build a base image for Windows and deploy it to $cloud when you need a new box. Vagrant can likely help you.
Sep 17 16:18:46 <learningc>	takamatsu, I see. I thought docker was an hypervisor of some kind where any applications can run natively on top of it
Sep 17 16:19:15 <learningc>	I probably got the wrong concept...
Sep 17 16:20:08 <tabakhase>	dude-x oh well depends how deep you go... me no frontend, so somewhat fixed screenshots are already awesomesauce to me ;D --- but i guess if youre in frontend and want to actually play around in your React-SPA smth like IE may be more interesting...
Sep 17 16:20:34 <tabakhase>	and then ye, vagrant & virtualbox is prob more way to go than docker
Sep 17 16:20:43 <dude-x>	tabakhase i don't do front end work, i "merely" do automation
Sep 17 16:21:19 <learningc>	ok, a headless without a monitor, but how do I see the browser?
Sep 17 16:21:45 <mgolisch>	you dont
Sep 17 16:21:49 <mgolisch>	its for automation
Sep 17 16:22:11 <dude-x>	learningc you don't. screenshots still work with browser automation
Sep 17 16:22:54 <dude-x>	learningc but with something like xvfb (X virtual framebuffer) you can use an X windows client and connect to the host and see the appplication
Sep 17 16:23:27 <dude-x>	actualy xvfb + vnc
Sep 17 16:23:45 <dude-x>	vnc gives you a window to look at the app, while just plain x will stream the UI to your desktop
Sep 17 16:24:17 <learningc>	so headless browsers using docker are not for regular internet users?
Sep 17 16:24:23 <dude-x>	learningc no.
Sep 17 16:24:40 <dude-x>	what good is a browser if you can't see it
Sep 17 16:24:50 <dude-x>	but if you need to run tests that your website is functionally properly
Sep 17 16:24:57 <dude-x>	then headless makes sense
Sep 17 16:25:05 <learningc>	ah
Sep 17 16:25:06 <dude-x>	because it's faster, and uses less resources
Sep 17 16:25:12 <dude-x>	or if you're scraping websites
Sep 17 16:25:58 <programmerq>	I've got a scraping project I want to do. I want to listen to the full archives of a podcast, but their rss feed is capped to only show the most recent x episodes, and they have about double that. I figure I can scrape and generate my own xml, lol.
Sep 17 16:26:15 <programmerq>	probably don't need a browser to do it though
Sep 17 16:26:56 <dude-x>	scrapy on Python has a pretty good api. it uses selenium/requests to get the job done
Sep 17 16:27:04 <tabakhase>	learningc random example: https://github.com/checkly/puppeteer-examples/blob/master/4.%20shopping-carts/walmart.js   --- this puts smth in your walmart onlineshop basket and makes a screenshot -- now your CI pipeline would do that, maybe compare the generated image with a older one you saved "golden master" - and trigger an alarm if "more than 1% difference" is found
Sep 17 16:27:23 <tabakhase>	and all of this can hapen "on some server in the cloud"
Sep 17 16:28:02 <dude-x>	image comparison tests are hard to maintain. for that my company pays for Applitools Eyes
Sep 17 16:28:12 <learningc>	dude-x, but why use a web browser to scrap websites? Can't these be done with programming languages to do these faster?
Sep 17 16:28:27 <dude-x>	learningc javascript can ruin your day
Sep 17 16:28:51 <dude-x>	learningc you can use a program to open a page but it won't execute the javascript that may render the URL or asset you're looking for.
Sep 17 16:29:09 <learningc>	dude-x, ah! good point!
Sep 17 16:29:15 <tabakhase>	dude-x how you feel on Applitools? -- im only getting into that whole visual stuff and it looked neat, but kinda little info & no demo... ((currently ive got some selfwritten stuff and csscritic for user-review))
Sep 17 16:30:11 <schangg>	I am building a docker FROM image debian:9 . According to dockerhub, that image was last updated 6 days ago. However, when I run an apt-get dist-upgrade it fetches around 150 packages...
Sep 17 16:30:27 <schangg>	that seems like a lot for an image that is 6 days old
Sep 17 16:30:51 <tabakhase>	schangg building with "--pull"?
Sep 17 16:31:05 <learningc>	What would be the best docker image I could use?
Sep 17 16:31:26 <Ckat>	is there a way to just use existing local images in a stack?
Sep 17 16:31:45 <mgolisch>	Ckat: why?
Sep 17 16:31:53 <mgolisch>	sounds like alot of work
Sep 17 16:31:57 <Ckat>	its a huge pain to get this ported to 3.0
Sep 17 16:32:06 <Ckat>	its just working at all rather
Sep 17 16:32:15 <schangg>	tabakhase no
Sep 17 16:32:31 <Ckat>	why is it alot of work to get a stack with local images? is that not an option?
Sep 17 16:32:48 <schangg>	tabakhase just docker build .
Sep 17 16:33:01 <tabakhase>	schangg "docker images debian" - you prob have some older version on disk, build with --pull or manually "docker pull IMAGE" dfirst
Sep 17 16:33:55 <tabakhase>	Ckat what does that even mean...? - build everything FROM scratch? "--no-pull"?
Sep 17 16:34:33 <tabakhase>	and no idea how "3.0" fits in any of this ;D
Sep 17 16:34:43 <mgolisch>	also not sure how that would help, the compose file would still require that 3.x format
Sep 17 16:34:56 <mgolisch>	when used with the docker stack deploy command
Sep 17 16:35:11 <Ckat>	what a pain
Sep 17 16:35:29 <learningc>	I still cannot understand. Why would we want to run an application in docker if docker image is generally linux based?
Sep 17 16:35:30 <tabakhase>	ohhhh now i understand - youre talking of "docker stack" - sorry, i didnt made that connection ;D
Sep 17 16:35:56 <tabakhase>	and not super painfull... you can run a registry in another docker in "just a click"...
Sep 17 16:36:00 <mgolisch>	learningc: because we want to run linux applications?
Sep 17 16:36:36 <learningc>	mgolisch, I mean at least running something, isn't it?
Sep 17 16:37:31 <Ckat>	the case I have is some images with docker images with compose 2.2 files, that I want to put in a single node swarm
Sep 17 16:37:41 <Ckat>	do I need a registry for this?
Sep 17 16:37:52 <mgolisch>	just run them as standalone containers?
Sep 17 16:38:02 <mgolisch>	if you dont require any swarm mode features
Sep 17 16:38:03 <Ckat>	people want to use secrets
Sep 17 16:38:21 <Ckat>	also they might want to use swarm features later, is what I was told
Sep 17 16:38:55 <Ckat>	kinda failing to see what the workflow is to set this up.. do I build the images off the existing compose files and make some local registry than put up a stack with that?
Sep 17 16:39:14 <tabakhase>	also sure you dont have a registry already?... most kube things come with one, gitlab comes with one, running your own is "a single docker run command" too...
Sep 17 16:39:17 <programmerq>	you don't need a registry for a single node swarm dev setup.
Sep 17 16:39:29 <programmerq>	just build the images locally and refer to them
Sep 17 16:39:57 <Ckat>	can I do that from a command or do I need seperate deploy-stack.yml files?
Sep 17 16:40:07 <mgolisch>	sure docker service create?
Sep 17 16:40:27 <programmerq>	Ckat▸ 'docker stack deploy' won't build images for you. you can build with 'docker-compose build' or 'docker build'
Sep 17 16:40:45 <programmerq>	or whatever other build process you'd like to use
Sep 17 16:41:22 <tabakhase>	so: "git clone && docker stack deploy" will not work -- but "git clone && dockr build && docker stack deploy" will be just fine?
Sep 17 16:41:37 <Ckat>	okay so build images with the docker-compose build. that creates my two images and sets up some volumes and networks. then is there a clean way to use that on a stack?
Sep 17 16:41:54 <programmerq>	docker-compose build does not set up volumes and networks-- it only builds images.
Sep 17 16:42:01 <mgolisch>	yes make a version 3.x compose file
Sep 17 16:42:22 <Ckat>	this is what I was trying to avoid
Sep 17 16:42:34 <programmerq>	why is that a problem?
Sep 17 16:42:57 <mgolisch>	because it uses properties not available in that version and they are too lazy to look for the approriate replacements
Sep 17 16:43:10 <programmerq>	Ckat▸ the cpu thing?
Sep 17 16:43:28 <programmerq>	just specify both cpu options-- the one for containers, and the one for swarm...
Sep 17 16:43:43 <Ckat>	I've set that with cpus and memory now, which were cpucount and mem_limit
Sep 17 16:44:00 <dude-x>	learningc the purpose of docker is many-fold. one is isolation of applications. when in a container they don't have access to other things, so if someone hacks the app the container is in, they will have access only to container resources. the other aspect is that of repeatability. A container should represent the same environment always, so that you can share with it other people or machines
Sep 17 16:44:32 <dude-x>	learningc and see that it runs the same. another aspect is that you can run multiple containers on the same machine
Sep 17 16:45:33 <learningc>	dude-x, how is that different from a VM?
Sep 17 16:45:47 <dude-x>	learningc a VM is essentially a computer in your computer
Sep 17 16:46:47 <learningc>	you mean a standalone os inside another os?
Sep 17 16:46:58 <dude-x>	from the point of view of a Linux host, a container is just a thing where files live and processes can run, but they can't access/see things out side of the walls you provide them
Sep 17 16:47:29 <dude-x>	containers can run different OSes but that's more of an implementation detail.
Sep 17 16:47:54 <tabakhase>	containers "dont run a OS at all" if you wanne be strict - only thing running in there is your app and only your app
Sep 17 16:48:14 <tabakhase>	so "debian" is "just there so you can use apt-get" and nothing more in a way :P
Sep 17 16:48:27 <programmerq>	learningc▸ a docker container doesn't get its own copy of the kernel. there is no virtual bios, no boot, no virtual hardware at all. instead, they use kernel features that section off the containerized process into its own corner-- on linux that's namespaces and cgroups.
Sep 17 16:48:29 <dude-x>	a VM actually emulates hardware. it has a bios, it can even emulate 32 bit CPUs if your CPU supports that
Sep 17 16:48:46 <dude-x>	a VM has a virtual harddrive
Sep 17 16:48:57 <dude-x>	a container on your machine exist on your harddrive, and you can look at the files.
Sep 17 16:49:18 <programmerq>	basically the containerized process is lied to by the host-- it makes a syscall like "hey, show me all the processes running on the system" and the kernel responds back with only processes in that container.
Sep 17 16:49:25 <programmerq>	it's still the same kernel that's running your whol host
Sep 17 16:49:46 <programmerq>	or put simply, it's a fancy way to run a process
Sep 17 16:50:10 <dude-x>	when i was a windows user, i dreamed of isolated apps. imagine being able to browser without getting pwned due to a bug in the browser
Sep 17 16:50:54 <dude-x>	but docker came to bsd/linux first.
Sep 17 16:51:06 <programmerq>	windows containers have two isolation modes. application isolation is the closest to what linux containers are like-- microsoft implemented their own containerization features in windows server 2016/2019 and docker uses those. It also has hyper-v isolation mode which is available on WS and windows 10 pro, and it feels like a container since the same interface is prosented to the user, but actually does use
Sep 17 16:51:08 <programmerq>	some virtualization. It doesn't show up as a vm in the hyper-v hypervisor utilities though.
Sep 17 16:52:13 <programmerq>	docker hasn't actually gone to bsd, to be fair. there have been some efforts to wrap docker around jail, but none that's been merged upstream. jails have been around on bsd for decades and definitely predate docker/lxc
Sep 17 16:52:19 <incognito>	programmerq: when network "bridge" : does docker integrate a dhcp ?
Sep 17 16:52:30 <programmerq>	incognito▸ docker does not use dhcp in its ipam
Sep 17 16:52:53 <learningc>	I see. Thanks for the explanations
Sep 17 16:52:55 <incognito>	programmerq: how does it know the next available ip to use ?
Sep 17 16:53:06 <programmerq>	it has its own ipam module built in.
Sep 17 16:53:33 <programmerq>	that way containers aren't on the hook to all have some sort of dhcp client-- by the time your containerized process starts, the network interface has been configured by docker already.
Sep 17 16:53:55 <incognito>	programmerq: if i create a new interface inside my container, i need to assign it manually, isn't it ?
Sep 17 16:54:11 <programmerq>	incognito▸ why not connect your container to a second docker network that has the configuration you need?
Sep 17 16:54:23 <incognito>	programmerq: vpn ^^
Sep 17 16:54:47 <incognito>	vpn to the isolated docker network
Sep 17 16:54:50 <learningc>	So I can use docker to replace a VM for non gui stuffs?
Sep 17 16:55:23 <programmerq>	incognito▸ if you run a vpn client in the container, then you'd be on the hook to configure it from within the container, yeah.
Sep 17 16:56:04 <incognito>	ok, thanks
Sep 17 16:56:59 <dude-x>	learningc depends on what you use the VM for
Sep 17 16:57:28 <learningc>	dude-x, I often build Linux distro from source on VM
Sep 17 16:57:51 <dude-x>	i would use a VM for that. but you can then take tailor that distro into a container image.
Sep 17 16:59:42 <learningc>	dude-x, the distro are more for embedded systems
Sep 17 16:59:55 <dude-x>	i see. i would use a vm for that
Sep 17 17:00:21 <dude-x>	but you can still contaiinerize your build system too
Sep 17 17:00:52 <learningc>	dude-x, in that case why VM is preferable?
Sep 17 17:01:17 <dude-x>	docker philosophy is about containerizing a single application
Sep 17 17:01:51 <dude-x>	you can have mutiple apps in a single container too but the idea is that an app can run, but then be torn down, and easily replaced letter with a better/newer version
Sep 17 17:03:30 <dude-x>	learningc i would imagine a build for a distro relies on a lot of tooling
Sep 17 17:03:56 <alexeightsix>	How come when i build an image locally vs on the server itself it produces different results?
Sep 17 17:04:26 <alexeightsix>	I'm getting this error ONLY on the server, locally I don't get any errors and i'm using the no-cache option
Sep 17 17:04:27 <alexeightsix>	: Unable to locate package libmariadb-client-lgpl-devE: Package 'mysql-client' has no installation candidate
Sep 17 17:06:49 <learningc>	dude-x, I use yocto for embedded. It's all automated once to configure the build script
Sep 17 17:08:00 <dude-x>	learningc i suppose you can run this script in a container.
Sep 17 17:08:55 <dude-x>	the advantage to a container instead of a VM is that it will use less memory, diskspace since you can only include the minimal set of files necessary
Sep 17 17:09:08 <dude-x>	but if you need to debug a broken build
Sep 17 17:09:11 <dude-x>	a VM feels more natural
Sep 17 17:10:21 <learningc>	Do we need to allocate a fix amount of diskspace with docker as we do with a VM?
Sep 17 17:10:55 <mgolisch>	alexeightsix: what are you building from?
Sep 17 17:11:11 <alexeightsix>	php frpm 7.1
Sep 17 17:13:00 <mgolisch>	cat /etc/debian_debian version?
Sep 17 17:13:04 <mgolisch>	ups
Sep 17 17:13:09 <mgolisch>	/etc/debian_version
Sep 17 17:13:37 <mgolisch>	might be just an old image already pulled based on a previous base distribution version
Sep 17 17:17:40 <ironfroggy>	I'm looking to clear up something about Docker for Windows (from WSL).
Sep 17 17:18:19 <ironfroggy>	I have a container with my CWD, my project folder, volume mounted inside it. If I do this with the directory sitting in WSL-space, then Docker for Windows can't see it.
Sep 17 17:18:36 <ironfroggy>	if I do this with the project sitting in Windows space, then Docker can see it but symlinks in the project don't work.
Sep 17 17:18:47 <ironfroggy>	So... is there a resolution for this?
Sep 17 17:19:23 <ironfroggy>	What's really bothering me is that I *did* have this exact project running with this setup before, but I'd reset my machine and was rebuilding my setup and now its not working and I don't know what's changed.
Sep 17 17:20:18 <mgolisch>	what is not working with symlinks?
Sep 17 17:20:29 <ironfroggy>	they appear as empty files
Sep 17 17:20:46 <ironfroggy>	Windows itself doesn't support symlinks
Sep 17 17:20:54 <ironfroggy>	only inside WSL
Sep 17 17:21:00 <mgolisch>	hm pretty sure it does
Sep 17 17:21:04 <mgolisch>	mklink.exe
Sep 17 17:21:40 <alexeightsix>	mgolisch
Sep 17 17:21:45 <ironfroggy>	but it doens't support linux symlinks
Sep 17 17:21:49 <mgolisch>	yeah no
Sep 17 17:21:55 <alexeightsix>	you're right, thx -- locally i did -pull and it produced the same results
Sep 17 17:25:21 <mgolisch>	ironfroggy: so you have symlinks in a mounted directory or what?
Sep 17 17:27:46 <ironfroggy>	yes, in the mounted C drive
Sep 17 17:29:30 <mgolisch>	pretty sure symlinks are just normal files
Sep 17 17:29:49 <AWizzArd>	I have a dockerized app that wants to connect to a server on port 5500 on localhost. I don't have this server running on local host, but I have an ssh tunnel that establishes the connection. How can I enable the app in the container to connect to _my_ localhost, port 5500?
Sep 17 17:29:54 <AWizzArd>	Can I do this only with --net=host?
Sep 17 17:30:20 <ironfroggy>	mgolisch, i don't know why you'd think that, but they aren't, but thanks anyway
Sep 17 17:32:45 <ironfroggy>	it looks like it was a git issue. re-cloning the repository from windows fixed the symlinks.
Sep 17 17:35:23 <mgolisch>	AWizzArd: yes
Sep 17 17:35:49 <mgolisch>	ironfroggy: cool
Sep 17 17:39:32 <mgolisch>	AWizzArd: cant you just change where it connects to?
Sep 17 17:40:07 <gsearle>	I want to use swap space but managinf Docker via Kubernetes. I'm thinking of using Docker swarm to get around Kubernetes buggy handeling of swap. Is there anything I should know before working on this?
Sep 17 17:49:02 <mgolisch>	gsearle: does swarm support everything you need?
Sep 17 17:50:55 <istop28>	Hey everyone. I have a question about general container efficacy. I understand how this technology can be used to expedite development and be used to scale up/down very quickly in conjunction with "cloud" technologies. How would containers be applied to enterprise application services? For example, if I were to run a Jira server or SQL server, what
Sep 17 17:50:55 <istop28>	are the benefits of doing it via containerization over normal provision/orchestration/deployment methods using a tool like Ansible?
Sep 17 17:54:58 <incognito>	istop28: you said almost all the quality of docker; deployment facilties, scaling; you can add some security (since it's an isolated container); networking simplicity (need of subnet,etc..), volume management (transparent mounting of network storage)
Sep 17 17:55:48 <incognito>	Ansible is designed for hybrid cloud management, it encapsulates the docker needs in it, so it's not really a good comparison
Sep 17 17:56:06 <incognito>	resource limits
Sep 17 17:56:32 <incognito>	many management + CI + logging tools
Sep 17 17:57:15 *	incognito is a good advertiser, isn't he ?
Sep 17 17:58:30 <incognito>	istop28: you can for example find a docker-compose file ready to deploy the whole jira stacks (backend, storage, frontend)
Sep 17 17:59:35 <incognito>	istop28: you can also inherit from this one and append your services or node (to an existing service)
Sep 17 18:00:22 <incognito>	if you trust the maintainer (there are docker certified image), it simplifies many tasks of the sys admins
Sep 17 18:00:34 <AWizzArd>	mgolisch: I sit at location A and have a location B which runs a PG DB. Now a dockerized app on AWS needs to access the DB. What I can do is to build a tunnel from A to B. And I setup a reverse tunnel from A to AWS.
Sep 17 18:01:07 <AWizzArd>	mgolisch: The consequence is that the dockerized app tries to connect to localhost:5432, which tunnels data to machine A, which forwards it to B.
Sep 17 18:01:17 <AWizzArd>	I am not sure that I can use the `host` setting on AWS.
Sep 17 18:02:20 <istop28>	incognito so from a practical standpoint docker is more suited for large distributed operations i.e. “we must create an info sys that supports 500 users with ability to grow” which would require development of docker files, programmatic provisioning etc. but then when the need for 500 more users occurs you can just run the files again. Rather
Sep 17 18:02:20 <istop28>	than do the manual work of getting a 500 person info sys up and working and then doing it again?
Sep 17 18:02:52 <istop28>	I do not understand your last point about inheritance
Sep 17 18:03:27 <incognito>	istop28: you can use existing certified image to base your project on it and enhance it
Sep 17 18:04:01 <mgolisch>	AWizzArd: why not?
Sep 17 18:04:14 <mgolisch>	if its just docker on an ec2 instance i dont see why that wouldnt work
Sep 17 18:04:56 <incognito>	istop28: some are using docker in all cases, it permits to stand with a clean and simple os with only the tools you need; another good point is the hability to use docker-swarm in order to scale up on different machines
Sep 17 18:05:55 <mgolisch>	AWizzArd: or create that tunnel in seperate container and put both into the same user defined network
Sep 17 18:06:16 <mgolisch>	then you dont have to run the container in the global network namespace
Sep 17 18:06:30 <incognito>	istop28: you can when you need add another machine to your swarm with ease : https://docs.docker.com/engine/swarm/swarm-tutorial/add-nodes/
Sep 17 18:06:54 <mekhami>	it's really frustrating how many problems i'm having getting a decent docker setup going for a relatively straight forward web app
Sep 17 18:07:15 <mgolisch>	its ususualy pretty simple
Sep 17 18:07:29 <mgolisch>	put stuff in image, run image, done
Sep 17 18:07:41 <mgolisch>	if its a straight forward web app
Sep 17 18:07:53 <incognito>	istop28: plus there are management tools capable to categorize your containers in a nice UI; if you want to share the swarm with other services
Sep 17 18:09:01 <mekhami>	i guess my definition of straight forward may be skewed though. It's a web app, it uses webpack, it's for local dev so i mount my files over (except node modules and build files that need to happen inside the image). but getting webpack to work (getting the right node modules mostly) is like pulling teeth!
Sep 17 18:09:42 <mgolisch>	the right modules?
Sep 17 18:09:55 <mgolisch>	that should all be in your package.json
Sep 17 18:09:57 <mekhami>	node_modules. dependencies.
Sep 17 18:10:05 <mgolisch>	and no diffrent from running the app not in docker
Sep 17 18:10:10 <istop28>	incognito great thank you so much for the information. I will look into the thing you told me about. I am curious about any use cases that are applied to enterprise computing like windows AD, exchange, etc. and if those things are being adopted to containers readily or if the old way is still pervasive.
Sep 17 18:10:26 <mekhami>	right, but in order to have the ones on your local machine not end up in the container, you have to have a volume in the container
Sep 17 18:10:31 <mekhami>	and that volume gets in weird screwy states
Sep 17 18:10:48 <mgolisch>	i just mount the whole thing in
Sep 17 18:10:54 <mgolisch>	and do all my debugging inside the container
Sep 17 18:11:01 <incognito>	istop28: you are welcome
Sep 17 18:11:11 <mekhami>	that doesn't work with node modules, some of those dependencies are built using OS bindings that can differ on host and image os
Sep 17 18:11:41 <mgolisch>	why not?
Sep 17 18:11:46 <mgolisch>	just never build it on the host,,
Sep 17 18:54:19 <Swahili>	Q: Let's say I have a Service that happens to be a http server that is serving 2 or more Apps configured by Port number. Would Traefik support that? Or I'd have to split into different Http servers?
Sep 17 18:54:30 <Swahili>	How does that work or where can I read or see an example for this sort of cases?
Sep 17 18:55:27 <Swahili>	Or which other options are there. What I'm thinking is that, I'd have to create multiple http servers for each app?
Sep 17 18:55:33 <Swahili>	Wrong?!
Sep 17 19:53:22 <programmerq>	Swahili▸ as far as I know it works just fine, you just need to use a separate set of labels with a different service name.
Sep 17 19:55:12 <Swahili>	programmerq: thanks for looking btw. Ok. I've now create two http services for each application. I'll try that later
Sep 17 20:16:40 <ironfroggy_>	i have an existing few services running that were spun up with docker-compose
Sep 17 20:16:58 <ironfroggy_>	how can i copy a file into a named service's container without modifying the docker-compose.yml?
Sep 17 20:28:07 <tabakhase>	ironfroggy_ crowbar style? "docker cp"?
Sep 17 20:29:10 <ironfroggy_>	yeah i think i figured out a decent construct
Sep 17 20:29:45 <ironfroggy_>	docker cp path/to/file $(docker-compose ps -q service):path/in/container
Sep 17 20:30:08 <tabakhase>	pretty much this yep
Sep 17 20:30:54 <tabakhase>	and hey, docker-compose cp issue is only 3 years old, so maybe well get it one day /s https://github.com/docker/compose/issues/3593
Sep 17 20:31:28 <ironfroggy_>	haha yeah i saw that
Sep 17 20:55:08 <effprime>	hello, I am setting up a container with postfix (SMTP server), working fine at the base level, and I have exposed 25:25 so I can send mail externally. when sending through localhost, it seems to NAT and report the source domain as "unknown"... this doesn't happen when not using a container (it just keeps the source as localhost), so is there a way
Sep 17 20:55:08 <effprime>	to configure docker to keep the domain?
Sep 17 20:56:45 <lmat>	Is round-robin DNS resolution default in docker swarm? That is, if I have a service with 2 replicas, the DNS server will return the IP address of one then the other?
Sep 17 21:00:54 <_Raijin>	If I am running a media server server with docker compose and I want to use a VPN for my media downloads, will this screw up my domain networking and my ability to connect to the server?
Sep 17 21:05:05 <tabakhase>	hell yea
Sep 17 21:05:33 <tabakhase>	docker is not made to hide in tor ;-) do it on the router infront of it or youll sink into madness
Sep 17 21:06:27 <tabakhase>	that is, all that is certainly possible, but "worth" na
Sep 17 21:09:11 <tabakhase>	effprime docker and mail is a bit special... (also expose is for "in", for "out" you dont need any ports at all) -- "simplest" would prob be to run it in the "host" network namespace... but its rly more a "not do final delivery from docker" ((as "outgoing ip" may be whatever.. and you likely have a static one with reputaton on your mailserver - or use smth like sendgrid/mailjet and whatanot...)
Sep 17 21:12:03 <effprime>	I am trying network mode host now, ty
Sep 17 21:12:11 <effprime>	ports seem to no longer be available though, interesting
Sep 17 21:13:13 <effprime>	ah nvm, its a direct port expose, nice
Sep 17 22:43:51 *	Disconnected ()
**** ENDING LOGGING AT Tue Sep 17 22:43:51 2019

**** BEGIN LOGGING AT Tue Sep 17 22:44:16 2019

Sep 17 22:44:16 *	Now talking on #docker
Sep 17 22:44:16 *	Topic for #docker is: Docker: Open platform for distributed applications | http://docker.com | Certifications https://success.docker.com/certification | http://github.com/moby/moby | Current Status: http://status.docker.com/ | https://forums.docker.com/ | Registration with NickServ required: https://freenode.net/kb/answer/registration
Sep 17 22:44:16 *	Topic for #docker set by programmerq!~jeff@unaffiliated/programmerq (Fri Dec  7 20:42:52 2018)
Sep 17 22:51:03 <SpeakerToMeat>	should services show up in docker ps?
Sep 17 22:52:20 <SpeakerToMeat>	Ah yes, yes they do
Sep 17 22:52:33 <SpeakerToMeat>	I guess the service's task shows on ps
**** ENDING LOGGING AT Tue Sep 17 22:58:02 2019

**** BEGIN LOGGING AT Tue Sep 17 22:58:02 2019

